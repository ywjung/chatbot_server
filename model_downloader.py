#!/usr/bin/env python3
"""
GGUF ëª¨ë¸ ë‹¤ìš´ë¡œë”
Qwen3-30B-A3B-Q4_K_M.gguf ëª¨ë¸ì„ ì•ˆì •ì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í”„ë¡œê·¸ë¨
"""

import os
import sys
import time
import json
import argparse
import hashlib
import logging
from pathlib import Path
from typing import Optional, Dict, Any
import requests
from tqdm import tqdm
from huggingface_hub import hf_hub_download, snapshot_download, HfApi
import urllib3
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('model_download.log')
    ]
)
logger = logging.getLogger(__name__)

class ModelDownloader:
    def __init__(self, models_dir: str = "./models"):
        """
        ëª¨ë¸ ë‹¤ìš´ë¡œë” ì´ˆê¸°í™”
        
        Args:
            models_dir: ëª¨ë¸ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬
        """
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(exist_ok=True)
        
        # ì„¸ì…˜ ì„¤ì • (ì¬ì‹œë„ ë° íƒ€ì„ì•„ì›ƒ)
        self.session = requests.Session()
        retry_strategy = Retry(
            total=5,
            backoff_factor=2,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)
        
        logger.info(f"ëª¨ë¸ ë‹¤ìš´ë¡œë” ì´ˆê¸°í™” ì™„ë£Œ. ì €ì¥ ë””ë ‰í† ë¦¬: {self.models_dir}")
    
    def get_model_info(self, repo_id: str) -> Dict[str, Any]:
        """HuggingFace ì €ì¥ì†Œì˜ ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
        try:
            api = HfApi()
            repo_info = api.repo_info(repo_id)
            
            files = []
            for sibling in repo_info.siblings:
                if sibling.rfilename.endswith('.gguf'):
                    files.append({
                        'filename': sibling.rfilename,
                        'size': getattr(sibling, 'size', 0),
                        'size_mb': round(getattr(sibling, 'size', 0) / (1024 * 1024), 1) if hasattr(sibling, 'size') else 'Unknown'
                    })
            
            return {
                'repo_id': repo_id,
                'total_files': len(files),
                'gguf_files': files
            }
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def download_with_progress(self, url: str, dest_path: Path, resume: bool = True) -> bool:
        """ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            headers = {}
            initial_pos = 0
            
            # ê¸°ì¡´ íŒŒì¼ì´ ìˆê³  resume=Trueì¸ ê²½ìš° ì´ì–´ë°›ê¸°
            if resume and dest_path.exists():
                initial_pos = dest_path.stat().st_size
                headers['Range'] = f'bytes={initial_pos}-'
                logger.info(f"ê¸°ì¡´ íŒŒì¼ ë°œê²¬. {initial_pos} ë°”ì´íŠ¸ë¶€í„° ì´ì–´ë°›ê¸° ì‹œì‘")
            
            response = self.session.get(url, headers=headers, stream=True, timeout=30)
            response.raise_for_status()
            
            # ì „ì²´ íŒŒì¼ í¬ê¸° ê³„ì‚°
            content_length = response.headers.get('content-length')
            if content_length:
                total_size = int(content_length) + initial_pos
            else:
                total_size = None
                logger.warning("íŒŒì¼ í¬ê¸°ë¥¼ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # íŒŒì¼ ì“°ê¸°
            mode = 'ab' if resume and initial_pos > 0 else 'wb'
            
            with open(dest_path, mode) as f:
                with tqdm(
                    initial=initial_pos,
                    total=total_size,
                    unit='B',
                    unit_scale=True,
                    unit_divisor=1024,
                    desc=dest_path.name
                ) as pbar:
                    
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            pbar.update(len(chunk))
            
            logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {dest_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def download_with_hf_hub(self, repo_id: str, filename: str, max_retries: int = 3) -> Optional[Path]:
        """HuggingFace Hubì„ ì‚¬ìš©í•œ ë‹¤ìš´ë¡œë“œ"""
        local_dir = self.models_dir / repo_id.replace("/", "--")
        
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ”„ HuggingFace Hub ë‹¤ìš´ë¡œë“œ ì‹œë„ {attempt + 1}/{max_retries}")
                logger.info(f"   ì €ì¥ì†Œ: {repo_id}")
                logger.info(f"   íŒŒì¼: {filename}")
                logger.info(f"   ì €ì¥ ìœ„ì¹˜: {local_dir}")
                
                downloaded_file = hf_hub_download(
                    repo_id=repo_id,
                    filename=filename,
                    local_dir=local_dir,
                    resume_download=True,
                    force_download=False,
                    local_files_only=False
                )
                
                if Path(downloaded_file).exists():
                    logger.info(f"âœ… HuggingFace Hub ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {downloaded_file}")
                    return Path(downloaded_file)
                
            except Exception as e:
                logger.warning(f"âš ï¸ HuggingFace Hub ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 10
                    logger.info(f"â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
        
        return None
    
    def download_with_snapshot(self, repo_id: str, max_retries: int = 2) -> Optional[Path]:
        """ì „ì²´ ì €ì¥ì†Œ ë‹¤ìš´ë¡œë“œ"""
        local_dir = self.models_dir / repo_id.replace("/", "--")
        
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ”„ ì „ì²´ ì €ì¥ì†Œ ë‹¤ìš´ë¡œë“œ ì‹œë„ {attempt + 1}/{max_retries}")
                
                downloaded_path = snapshot_download(
                    repo_id=repo_id,
                    local_dir=local_dir,
                    resume_download=True
                )
                
                logger.info(f"âœ… ì „ì²´ ì €ì¥ì†Œ ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {downloaded_path}")
                return Path(downloaded_path)
                
            except Exception as e:
                logger.warning(f"âš ï¸ ì „ì²´ ì €ì¥ì†Œ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 15
                    logger.info(f"â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
        
        return None
    
    def verify_file(self, file_path: Path, expected_size: Optional[int] = None) -> bool:
        """ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ê²€ì¦"""
        if not file_path.exists():
            logger.error(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")
            return False
        
        actual_size = file_path.stat().st_size
        logger.info(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {actual_size:,} bytes ({actual_size / (1024**3):.2f} GB)")
        
        if expected_size and actual_size != expected_size:
            logger.warning(f"âš ï¸ íŒŒì¼ í¬ê¸° ë¶ˆì¼ì¹˜. ì˜ˆìƒ: {expected_size:,}, ì‹¤ì œ: {actual_size:,}")
            return False
        
        # íŒŒì¼ì´ ì˜¬ë°”ë¥¸ GGUF í˜•ì‹ì¸ì§€ í™•ì¸
        try:
            with open(file_path, 'rb') as f:
                header = f.read(8)
                if header.startswith(b'GGUF'):
                    logger.info("âœ… ì˜¬ë°”ë¥¸ GGUF íŒŒì¼ í˜•ì‹ í™•ì¸")
                    return True
                else:
                    logger.error("âŒ ì˜¬ë°”ë¥´ì§€ ì•Šì€ GGUF íŒŒì¼ í˜•ì‹")
                    return False
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def download_model(self, repo_id: str, filename: str, force_redownload: bool = False) -> bool:
        """
        ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë©”ì¸ í•¨ìˆ˜
        
        Args:
            repo_id: HuggingFace ì €ì¥ì†Œ ID
            filename: ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ëª…
            force_redownload: ê¸°ì¡´ íŒŒì¼ì´ ìˆì–´ë„ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œí• ì§€ ì—¬ë¶€
        
        Returns:
            bool: ë‹¤ìš´ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        print("=" * 80)
        print(f"ğŸ¤– GGUF ëª¨ë¸ ë‹¤ìš´ë¡œë”")
        print("=" * 80)
        print(f"ğŸ“¦ ì €ì¥ì†Œ: {repo_id}")
        print(f"ğŸ“„ íŒŒì¼: {filename}")
        print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {self.models_dir}")
        print("=" * 80)
        
        # ìµœì¢… íŒŒì¼ ê²½ë¡œ
        final_dir = self.models_dir / repo_id.replace("/", "--")
        final_path = final_dir / filename
        
        # ê¸°ì¡´ íŒŒì¼ í™•ì¸
        if final_path.exists() and not force_redownload:
            logger.info(f"âœ… íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {final_path}")
            if self.verify_file(final_path):
                print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! íŒŒì¼ ìœ„ì¹˜: {final_path}")
                return True
            else:
                logger.warning("âš ï¸ ê¸°ì¡´ íŒŒì¼ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")
        
        # ëª¨ë¸ ì •ë³´ ì¡°íšŒ
        logger.info("ğŸ” ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì¤‘...")
        model_info = self.get_model_info(repo_id)
        if model_info:
            print(f"ğŸ“Š ì €ì¥ì†Œ ì •ë³´:")
            print(f"   - ì „ì²´ GGUF íŒŒì¼: {model_info['total_files']}ê°œ")
            for file_info in model_info['gguf_files']:
                marker = " â­" if file_info['filename'] == filename else ""
                print(f"   - {file_info['filename']}: {file_info['size_mb']} MB{marker}")
            print()
        
        # ë‹¤ìš´ë¡œë“œ ì‹œë„ 1: HuggingFace Hub (ê¶Œì¥)
        logger.info("ğŸš€ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        downloaded_path = self.download_with_hf_hub(repo_id, filename)
        
        if downloaded_path and self.verify_file(downloaded_path):
            print(f"âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ! íŒŒì¼ ìœ„ì¹˜: {downloaded_path}")
            return True
        
        # ë‹¤ìš´ë¡œë“œ ì‹œë„ 2: ì „ì²´ ì €ì¥ì†Œ ë‹¤ìš´ë¡œë“œ
        logger.info("ğŸ”„ ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ ì „ì²´ ì €ì¥ì†Œ ë‹¤ìš´ë¡œë“œ ì‹œë„...")
        downloaded_path = self.download_with_snapshot(repo_id)
        
        if downloaded_path:
            target_file = downloaded_path / filename
            if target_file.exists() and self.verify_file(target_file):
                print(f"âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ! íŒŒì¼ ìœ„ì¹˜: {target_file}")
                return True
        
        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨
        logger.error("âŒ ëª¨ë“  ë‹¤ìš´ë¡œë“œ ë°©ë²•ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("\n" + "=" * 80)
        print("âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        print("=" * 80)
        print("ğŸ’¡ ë¬¸ì œ í•´ê²° ë°©ë²•:")
        print("1. ì¸í„°ë„· ì—°ê²° í™•ì¸")
        print("2. VPN ì‚¬ìš© ì‹œ ë¹„í™œì„±í™”")
        print("3. DNS ì„¤ì • í™•ì¸ (8.8.8.8, 8.8.4.4)")
        print("4. HuggingFace CLIë¡œ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ:")
        print(f"   huggingface-cli download {repo_id} {filename} --local-dir {final_dir}")
        print("=" * 80)
        return False

def main():
    parser = argparse.ArgumentParser(description="GGUF ëª¨ë¸ ë‹¤ìš´ë¡œë”")
    parser.add_argument(
        "--repo-id", 
        default="lmstudio-community/Qwen3-30B-A3B-GGUF",
        help="HuggingFace ì €ì¥ì†Œ ID"
    )
    parser.add_argument(
        "--filename", 
        default="Qwen3-30B-A3B-Q4_K_M.gguf",
        help="ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ëª…"
    )
    parser.add_argument(
        "--models-dir",
        default="./models",
        help="ëª¨ë¸ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="ê¸°ì¡´ íŒŒì¼ì´ ìˆì–´ë„ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ"
    )
    parser.add_argument(
        "--list-files",
        action="store_true",
        help="ì‚¬ìš© ê°€ëŠ¥í•œ GGUF íŒŒì¼ ëª©ë¡ë§Œ í‘œì‹œ"
    )
    
    args = parser.parse_args()
    
    downloader = ModelDownloader(args.models_dir)
    
    # íŒŒì¼ ëª©ë¡ë§Œ í‘œì‹œ
    if args.list_files:
        print("ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ GGUF íŒŒì¼ ì¡°íšŒ ì¤‘...")
        model_info = downloader.get_model_info(args.repo_id)
        if model_info:
            print(f"\nğŸ“¦ {args.repo_id}")
            print("=" * 60)
            for file_info in model_info['gguf_files']:
                print(f"ğŸ“„ {file_info['filename']}")
                print(f"   í¬ê¸°: {file_info['size_mb']} MB")
                print()
        return
    
    # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    success = downloader.download_model(args.repo_id, args.filename, args.force)
    
    if success:
        print("\nğŸ‰ ë‹¤ìš´ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ì´ì œ RAG ì„œë²„ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    else:
        print("\nâŒ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)

if __name__ == "__main__":
    main()