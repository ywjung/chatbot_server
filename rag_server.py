import json
import os
import glob
import chromadb
from sentence_transformers import SentenceTransformer
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from fastapi.openapi.docs import get_swagger_ui_html, get_redoc_html
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional, Union
import requests
import logging
import uuid
import time
import re
import uvicorn
import numpy as np

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Pydantic ëª¨ë¸ ì •ì˜
class SearchRequest(BaseModel):
    query: str = Field(..., description="ê²€ìƒ‰í•  ì§ˆì˜", example="íœ´ê°€ ì‹ ì²­ ë°©ë²•")
    top_k: int = Field(20, description="ë°˜í™˜í•  ê²°ê³¼ ìˆ˜", example=20, ge=1, le=50)
    main_category_filter: Optional[str] = Field(None, description="ëŒ€ë¶„ë¥˜ í•„í„°", example="ì¸ì‚¬")

class ConversationMessage(BaseModel):
    """ëŒ€í™” ë©”ì‹œì§€ ëª¨ë¸"""
    role: str = Field(..., description="ë©”ì‹œì§€ ì—­í•  (user ë˜ëŠ” assistant)", example="user")
    content: str = Field(..., description="ë©”ì‹œì§€ ë‚´ìš©", example="íœ´ê°€ ì‹ ì²­ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?")
    context: Optional[List[Dict[str, Any]]] = Field(None, description="ì‘ë‹µ ì»¨í…ìŠ¤íŠ¸ (assistant ë©”ì‹œì§€ì¸ ê²½ìš°)")

class ChatRequest(BaseModel):
    query: str = Field(..., description="ì§ˆë¬¸ ë‚´ìš©", example="21ë…„ì°¨ íœ´ê°€ëŠ” ë©°ì¹ ì¸ê°€ìš”?", min_length=1)
    main_category_filter: Optional[str] = Field(None, description="ëŒ€ë¶„ë¥˜ í•„í„°", example="ì¸ì‚¬")
    conversation_history: List[ConversationMessage] = Field(
        default_factory=list, 
        description="ì´ì „ ëŒ€í™” ê¸°ë¡",
        example=[
            {
                "role": "user",
                "content": "íœ´ê°€ ì‹ ì²­ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"
            },
            {
                "role": "assistant", 
                "content": "íœ´ê°€ ì‹ ì²­ì€ ì „ìê²°ì¬ ì‹œìŠ¤í…œì„ í†µí•´ ì§„í–‰ë©ë‹ˆë‹¤.",
                "context": []
            }
        ]
    )

class StreamChatRequest(BaseModel):
    """ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì „ìš© ìš”ì²­ ëª¨ë¸ (ë” ê´€ëŒ€í•œ ê²€ì¦)"""
    query: str = Field(..., description="ì§ˆë¬¸ ë‚´ìš©", example="21ë…„ì°¨ íœ´ê°€ëŠ” ë©°ì¹ ì¸ê°€ìš”?", min_length=1)
    main_category_filter: Optional[str] = Field(None, description="ëŒ€ë¶„ë¥˜ í•„í„°", example="ì¸ì‚¬")
    conversation_history: Optional[List[Dict[str, Any]]] = Field(
        default_factory=list,
        description="ì´ì „ ëŒ€í™” ê¸°ë¡ (ìœ ì—°í•œ í˜•ì‹)",
        example=[
            {"role": "user", "content": "íœ´ê°€ ì‹ ì²­ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"},
            {"role": "assistant", "content": "íœ´ê°€ ì‹ ì²­ì€ ì „ìê²°ì¬ ì‹œìŠ¤í…œì„ í†µí•´ ì§„í–‰ë©ë‹ˆë‹¤."}
        ]
    )

class SimpleTestRequest(BaseModel):
    """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìš”ì²­ ëª¨ë¸"""
    query: str = Field(..., description="ì§ˆë¬¸", example="íœ´ê°€ ì‹ ì²­ ë°©ë²•", min_length=1)
    category: Optional[str] = Field(None, description="ì¹´í…Œê³ ë¦¬ í•„í„°", example="ì¸ì‚¬")

class SearchResult(BaseModel):
    main_category: str
    sub_category: str
    question: str
    answer: str
    source_file: str
    chunk_type: str
    score: float
    rank: int

class HealthResponse(BaseModel):
    status: str
    rag_ready: bool
    regulations_count: int
    main_categories_count: int
    chunk_statistics: Optional[Dict[str, int]] = None
    improvements: str
    enhanced_features: Optional[List[str]] = None

class SearchResponse(BaseModel):
    query: str
    results: List[SearchResult]
    count: int
    main_category_filter: Optional[str]
    search_type: str
    min_relevance: float
    enhanced_features: List[str]

class ChatResponse(BaseModel):
    query: str
    response: str
    context: List[SearchResult]
    context_count: int
    context_quality: Dict[str, int]
    search_type: str
    response_type: str
    enhanced_features: List[str]

class CompanyRegulationsRAGSystem:
    def __init__(self, model_name: str = "nlpai-lab/KURE-v1", persist_directory: str = "./chroma_db"):
        """
        ê°œì„ ëœ ChromaDB ê¸°ë°˜ íšŒì‚¬ ì „ì²´ ë‚´ê·œ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (í–¥ìƒëœ ê²€ìƒ‰ ë° ì •ë³´ëŸ‰)

        Args:
            model_name: HuggingFace ëª¨ë¸ ì´ë¦„ ë˜ëŠ” ë¡œì»¬ ë””ë ‰í† ë¦¬ ì´ë¦„
            persist_directory: ChromaDB ì €ì¥ ë””ë ‰í† ë¦¬
        """
        model_path = os.path.join("./models", model_name.replace("/", "-"))

        # ë¡œì»¬ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ ë¡œë“œ ë˜ëŠ” ë‹¤ìš´ë¡œë“œ
        if not os.path.exists(model_path):
            logger.info(f"ğŸ“¦ ë¡œì»¬ì— ëª¨ë¸ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Hugging Faceì—ì„œ '{model_name}' ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...")
            try:
                model = SentenceTransformer(model_name)
                model.save(model_path)
                logger.info(f"âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥ ì™„ë£Œ: {model_path}")
            except Exception as e:
                logger.error(f"âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)
                raise
        else:
            logger.info(f"ğŸ”„ ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ: {model_path}")

        # ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
        self.model = SentenceTransformer(model_path)
        self.persist_directory = persist_directory

        # ChromaDB ì´ˆê¸°í™” (ê°œì„ ëœ ì˜¤ë¥˜ ì²˜ë¦¬)
        self.chroma_client = chromadb.PersistentClient(path=self.persist_directory)
        try:
            self.collection = self.chroma_client.get_collection(name="company_regulations")
            logger.info("ğŸ“ ê¸°ì¡´ company_regulations ì»¬ë ‰ì…˜ ë¡œë“œ ì™„ë£Œ")
        except Exception as get_error:
            logger.info(f"ğŸ“ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì—†ìŒ ë˜ëŠ” ì˜¤ë¥˜ ({get_error}), ìƒˆ ì»¬ë ‰ì…˜ ìƒì„± ì¤‘...")
            try:
                self.collection = self.chroma_client.create_collection(
                    name="company_regulations",
                    metadata={"description": "í–¥ìƒëœ íšŒì‚¬ ì „ì²´ ë‚´ê·œ ë²¡í„° ê²€ìƒ‰ ì»¬ë ‰ì…˜"}
                )
                logger.info("ğŸ“ ìƒˆë¡œìš´ company_regulations ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ")
            except Exception as create_error:
                logger.error(f"âŒ ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {create_error}")
                # ëŒ€ì•ˆìœ¼ë¡œ ì„ì‹œ ì´ë¦„ ì‚¬ìš©
                import time
                temp_name = f"company_regulations_temp_{int(time.time())}"
                logger.info(f"ğŸ”„ ì„ì‹œ ì»¬ë ‰ì…˜ '{temp_name}' ìƒì„± ì‹œë„...")
                self.collection = self.chroma_client.create_collection(
                    name=temp_name,
                    metadata={"description": "ì„ì‹œ íšŒì‚¬ ë‚´ê·œ ë²¡í„° ê²€ìƒ‰ ì»¬ë ‰ì…˜"}
                )
                logger.info(f"ğŸ“ ì„ì‹œ ì»¬ë ‰ì…˜ '{temp_name}' ìƒì„± ì™„ë£Œ")

        logger.info(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        logger.info(f"ğŸ’¾ ChromaDB ì €ì¥ ë””ë ‰í† ë¦¬: {self.persist_directory}")
    
    def load_company_regulations_data(self, data_directory: str = "./data_json"):
        """íšŒì‚¬ ì „ì²´ ë‚´ê·œ ë°ì´í„° ë¡œë“œ - í–¥ìƒëœ ì²­í‚¹ ì „ëµ"""
        logger.info(f"íšŒì‚¬ ì „ì²´ ë‚´ê·œ ë°ì´í„° ë¡œë“œ ì‹œì‘: {data_directory}")
        try:
            if not os.path.exists(data_directory):
                logger.error(f"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {data_directory}")
                return False
            
            json_files = glob.glob(os.path.join(data_directory, "*.json"))
            
            if not json_files:
                logger.warning(f"âš ï¸ {data_directory} ë””ë ‰í† ë¦¬ì—ì„œ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            logger.info(f"ğŸ” ë°œê²¬ëœ JSON íŒŒì¼: {len(json_files)}ê°œ")
            
            self.regulations_data = []
            self.main_categories = {}
            
            for json_file in json_files:
                file_name = os.path.basename(json_file)
                main_category = os.path.splitext(file_name)[0]
                
                logger.info(f"ğŸ“‚ ë¡œë”© ì¤‘: {file_name} â†’ ëŒ€êµ¬ë¶„: {main_category}")
                
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    category_count = 0
                    faq_count = 0
                    
                    for category_section in data:
                        sub_category = category_section['category']
                        category_count += 1
                        
                        for faq in category_section['faqs']:
                            question = faq['question']
                            answer = faq['answer']
                            
                            # ê¸°ë³¸ Q&A ë‹¨ìœ„ ì €ì¥
                            base_id = str(uuid.uuid4())
                            regulation_item = {
                                'id': base_id,
                                'main_category': main_category,
                                'sub_category': sub_category,
                                'question': question,
                                'answer': answer,
                                'text': f"{question} {answer}",
                                'source_file': file_name,
                                'chunk_type': 'qa_full',
                                'chunk_id': 0
                            }
                            self.regulations_data.append(regulation_item)
                            
                            # í–¥ìƒëœ ì²­í‚¹: ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë¶„ë¦¬í•˜ì—¬ ì¶”ê°€ ì €ì¥
                            # 1) ì§ˆë¬¸ ì¤‘ì‹¬ ì²­í¬
                            question_item = {
                                'id': f"{base_id}_q",
                                'main_category': main_category,
                                'sub_category': sub_category,
                                'question': question,
                                'answer': answer,
                                'text': f"ì§ˆë¬¸: {question}",
                                'source_file': file_name,
                                'chunk_type': 'question_focused',
                                'chunk_id': 1
                            }
                            self.regulations_data.append(question_item)
                            
                            # 2) ë‹µë³€ ì¤‘ì‹¬ ì²­í¬
                            answer_item = {
                                'id': f"{base_id}_a",
                                'main_category': main_category,
                                'sub_category': sub_category,
                                'question': question,
                                'answer': answer,
                                'text': f"ë‹µë³€: {answer} (ê´€ë ¨ ì§ˆë¬¸: {question})",
                                'source_file': file_name,
                                'chunk_type': 'answer_focused',
                                'chunk_id': 2
                            }
                            self.regulations_data.append(answer_item)
                            
                            # 3) ê¸´ ë‹µë³€ì¸ ê²½ìš° ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì¶”ê°€ ì €ì¥
                            if len(answer) > 200:  # ê¸´ ë‹µë³€ì¸ ê²½ìš°
                                sentences = re.split(r'[.!?]\s+', answer)
                                for i, sentence in enumerate(sentences):
                                    if len(sentence.strip()) > 20:  # ì˜ë¯¸ìˆëŠ” ë¬¸ì¥ë§Œ
                                        sentence_item = {
                                            'id': f"{base_id}_s{i}",
                                            'main_category': main_category,
                                            'sub_category': sub_category,
                                            'question': question,
                                            'answer': answer,
                                            'text': f"{sentence.strip()} (ì¶œì²˜: {question})",
                                            'source_file': file_name,
                                            'chunk_type': 'sentence_level',
                                            'chunk_id': 10 + i
                                        }
                                        self.regulations_data.append(sentence_item)
                            
                            faq_count += 1
                    
                    self.main_categories[main_category] = {
                        'file_name': file_name,
                        'sub_categories': category_count,
                        'total_faqs': faq_count
                    }
                    
                    logger.info(f"  â†’ ì†Œêµ¬ë¶„: {category_count}ê°œ, ê·œì •: {faq_count}ê°œ ë¡œë“œë¨")
                    
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨ {json_file}: {e}", exc_info=True)
                    continue
                except Exception as e:
                    logger.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {json_file}: {e}", exc_info=True)
                    continue
            
            total_chunks = len(self.regulations_data)
            total_files = len(self.main_categories)
            
            logger.info(f"âœ… íšŒì‚¬ ì „ì²´ ë‚´ê·œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
            logger.info(f"  - ëŒ€êµ¬ë¶„(íŒŒì¼): {total_files}ê°œ")
            logger.info(f"  - ì´ ì²­í¬: {total_chunks}ê°œ (í–¥ìƒëœ ì²­í‚¹ ì ìš©)")
            
            # ì²­í‚¹ íƒ€ì…ë³„ í†µê³„
            chunk_stats = {}
            for item in self.regulations_data:
                chunk_type = item.get('chunk_type', 'unknown')
                chunk_stats[chunk_type] = chunk_stats.get(chunk_type, 0) + 1
            
            for chunk_type, count in chunk_stats.items():
                logger.info(f"  - {chunk_type}: {count}ê°œ")
            
            return total_chunks > 0
            
        except Exception as e:
            logger.error(f"âŒ íšŒì‚¬ ë‚´ê·œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)
            return False

    def _clear_collection_safely(self):
        """ì»¬ë ‰ì…˜ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ì‚­ì œ"""
        try:
            # ë°©ë²• 1: ëª¨ë“  IDë¥¼ ê°€ì ¸ì™€ì„œ ê°œë³„ ì‚­ì œ ì‹œë„
            try:
                logger.info("ğŸ”„ ë°©ë²• 1: ê°œë³„ ID ì‚­ì œ ì‹œë„...")
                all_results = self.collection.get()
                if all_results and 'ids' in all_results and all_results['ids']:
                    batch_size = 1000
                    total_ids = all_results['ids']
                    
                    for i in range(0, len(total_ids), batch_size):
                        batch_ids = total_ids[i:i+batch_size]
                        self.collection.delete(ids=batch_ids)
                        logger.info(f"   ì‚­ì œ ë°°ì¹˜ {i//batch_size + 1}: {len(batch_ids)}ê°œ ID")
                    
                    logger.info("âœ… ê°œë³„ ID ì‚­ì œ ì™„ë£Œ")
                    return True
            except Exception as e:
                logger.warning(f"âš ï¸ ê°œë³„ ID ì‚­ì œ ì‹¤íŒ¨: {e}")
            
            # ë°©ë²• 2: ì»¬ë ‰ì…˜ ì¬ìƒì„±
            try:
                logger.info("ğŸ”„ ë°©ë²• 2: ì»¬ë ‰ì…˜ ì¬ìƒì„± ì‹œë„...")
                collection_name = self.collection.name
                collection_metadata = self.collection.metadata
                
                # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ
                self.chroma_client.delete_collection(name=collection_name)
                logger.info(f"   ê¸°ì¡´ ì»¬ë ‰ì…˜ '{collection_name}' ì‚­ì œ ì™„ë£Œ")
                
                # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
                self.collection = self.chroma_client.create_collection(
                    name=collection_name,
                    metadata=collection_metadata or {"description": "í–¥ìƒëœ íšŒì‚¬ ì „ì²´ ë‚´ê·œ ë²¡í„° ê²€ìƒ‰ ì»¬ë ‰ì…˜"}
                )
                logger.info(f"   ìƒˆ ì»¬ë ‰ì…˜ '{collection_name}' ìƒì„± ì™„ë£Œ")
                return True
                
            except Exception as e:
                logger.warning(f"âš ï¸ ì»¬ë ‰ì…˜ ì¬ìƒì„± ì‹¤íŒ¨: {e}")
            
            # ë°©ë²• 3: ìƒˆë¡œìš´ ì´ë¦„ìœ¼ë¡œ ì»¬ë ‰ì…˜ ìƒì„±
            try:
                logger.info("ğŸ”„ ë°©ë²• 3: ìƒˆ ì´ë¦„ìœ¼ë¡œ ì»¬ë ‰ì…˜ ìƒì„±...")
                import time
                new_collection_name = f"company_regulations_{int(time.time())}"
                
                self.collection = self.chroma_client.create_collection(
                    name=new_collection_name,
                    metadata={"description": "í–¥ìƒëœ íšŒì‚¬ ì „ì²´ ë‚´ê·œ ë²¡í„° ê²€ìƒ‰ ì»¬ë ‰ì…˜ (ì¬ìƒì„±)"}
                )
                logger.info(f"   ìƒˆ ì»¬ë ‰ì…˜ '{new_collection_name}' ìƒì„± ì™„ë£Œ")
                return True
                
            except Exception as e:
                logger.error(f"âŒ ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±ë„ ì‹¤íŒ¨: {e}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ì»¬ë ‰ì…˜ ì •ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
            return False
    
    def build_index(self):
        """ChromaDB ì¸ë±ìŠ¤ êµ¬ì¶• (ê°œì„ ëœ ì˜¤ë¥˜ ì²˜ë¦¬)"""
        logger.info("ChromaDB ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œì‘")
        try:
            if not hasattr(self, 'regulations_data') or not self.regulations_data:
                logger.warning("âš ï¸ ë¡œë“œëœ ë‚´ê·œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € load_company_regulations_data()ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")
                return False

            existing_count = self.collection.count()
            if existing_count > 0:
                logger.info(f"ğŸ” ê¸°ì¡´ ì¸ë±ìŠ¤ ë°œê²¬: {existing_count}ê°œ ë²¡í„°")
                if existing_count == len(self.regulations_data):
                    logger.info("â„¹ï¸ ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤. ì¬êµ¬ì¶•ì„ ê±´ë„ˆëœ€.")
                    return True
                else:
                    logger.info("ğŸ”„ ë‚´ê·œ ë°ì´í„°ê°€ ë³€ê²½ë˜ì–´ ì¸ë±ìŠ¤ë¥¼ ì¬êµ¬ì¶•í•©ë‹ˆë‹¤. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘...")
                    if not self._clear_collection_safely():
                        logger.error("âŒ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨")
                        return False
                    logger.info("âœ… ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ.")
            
            texts = [item['text'] for item in self.regulations_data]
            metadatas = [
                {
                    'main_category': item['main_category'],
                    'sub_category': item['sub_category'],
                    'question': item['question'],
                    'answer': item['answer'],
                    'source_file': item['source_file'],
                    'chunk_type': item.get('chunk_type', 'qa_full'),
                    'chunk_id': item.get('chunk_id', 0)
                } 
                for item in self.regulations_data
            ]
            ids = [item['id'] for item in self.regulations_data]
            
            logger.info(f"âš™ï¸ í…ìŠ¤íŠ¸ ì„ë² ë”© ë° ChromaDB ì €ì¥ ì¤‘... (ì´ {len(texts)}ê°œ ì²­í¬)")
            
            batch_size = 500
            total_batches = (len(texts) + batch_size - 1) // batch_size
            
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i+batch_size]
                batch_metadatas = metadatas[i:i+batch_size]
                batch_ids = ids[i:i+batch_size]
                
                try:
                    embeddings = self.model.encode(batch_texts, show_progress_bar=False).tolist()
                    
                    self.collection.add(
                        documents=batch_texts,
                        metadatas=batch_metadatas,
                        embeddings=embeddings,
                        ids=batch_ids
                    )
                    
                    logger.info(f"ğŸ“¦ ë°°ì¹˜ {i//batch_size + 1}/{total_batches} ì²˜ë¦¬ ì™„ë£Œ ({len(batch_texts)}ê°œ ì²­í¬)")
                    
                except Exception as batch_error:
                    logger.error(f"âŒ ë°°ì¹˜ {i//batch_size + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {batch_error}")
                    # ê°œë³„ í•­ëª© ì²˜ë¦¬ ì‹œë„
                    for j, (text, metadata, id_val) in enumerate(zip(batch_texts, batch_metadatas, batch_ids)):
                        try:
                            embedding = self.model.encode([text]).tolist()
                            self.collection.add(
                                documents=[text],
                                metadatas=[metadata],
                                embeddings=embedding,
                                ids=[id_val]
                            )
                        except Exception as item_error:
                            logger.warning(f"âš ï¸ ê°œë³„ í•­ëª© {i+j+1} ì²˜ë¦¬ ì‹¤íŒ¨: {item_error}")
                            continue
            
            final_count = self.collection.count()
            logger.info(f"âœ… ChromaDB ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {final_count}ê°œ ë²¡í„° ì €ì¥ë¨.")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {e}", exc_info=True)
            return False
    
    def _generate_query_variants(self, query: str) -> List[str]:
        """ì¿¼ë¦¬ ë³€í˜• ìƒì„±ìœ¼ë¡œ ë‹¤ì–‘í•œ ê°ë„ì—ì„œ ê²€ìƒ‰"""
        variants = [query]  # ì›ë³¸ ì¿¼ë¦¬
        
        # ì˜ë¬¸ì‚¬ ì œê±°í•œ ë²„ì „
        question_words = ['ë¬´ì—‡', 'ì–´ë–»ê²Œ', 'ì–¸ì œ', 'ì–´ë””ì„œ', 'ì™œ', 'ëˆ„ê°€', 'ì–¼ë§ˆë‚˜', 'ëª‡']
        cleaned_query = query
        for word in question_words:
            cleaned_query = cleaned_query.replace(word, '').strip()
        if cleaned_query and cleaned_query != query:
            variants.append(cleaned_query)
        
        # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œí•œ ë²„ì „
        keywords = re.findall(r'\b[ê°€-í£]{2,}\b', query)  # í•œê¸€ 2ê¸€ì ì´ìƒ í‚¤ì›Œë“œ
        if len(keywords) >= 2:
            keyword_query = ' '.join(keywords[:3])  # ìƒìœ„ 3ê°œ í‚¤ì›Œë“œ
            variants.append(keyword_query)
        
        # ë¬¸ì œ/ìƒí™© ì¤‘ì‹¬ ë³€í˜•
        if 'ë¬¸ì œ' in query or 'ì´ìŠˆ' in query or 'íŠ¸ëŸ¬ë¸”' in query:
            variants.append(query.replace('ë¬¸ì œ', 'í•´ê²°').replace('ì´ìŠˆ', 'ëŒ€ì‘').replace('íŠ¸ëŸ¬ë¸”', 'ì²˜ë¦¬'))
        
        # ì ˆì°¨/ë°©ë²• ì¤‘ì‹¬ ë³€í˜•
        if 'ë°©ë²•' in query or 'ì ˆì°¨' in query or 'ê³¼ì •' in query:
            procedure_query = query.replace('ë°©ë²•', 'ì ˆì°¨ ë‹¨ê³„').replace('ê³¼ì •', 'ì ˆì°¨')
            variants.append(procedure_query)
        
        return list(set(variants))  # ì¤‘ë³µ ì œê±°
    
    def search_with_enhanced_retrieval(self, query: str, top_k: int = 20, main_category_filter: str = None, min_relevance_score: float = 0.3) -> List[Dict[str, Any]]:
        """í–¥ìƒëœ ê²€ìƒ‰ - ë‹¤ì¤‘ ì¿¼ë¦¬, í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰, í–¥ìƒëœ ì¬ë­í‚¹ (í™•ì¥ëœ ì •ë³´ëŸ‰)"""
        logger.info(f"í–¥ìƒëœ RAG ê²€ìƒ‰: '{query[:50]}...', í•„í„°='{main_category_filter}', top_k={top_k}")
        try:
            if self.collection.count() == 0:
                logger.warning("âš ï¸ ì¸ë±ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return []
            
            # 1. ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±
            query_variants = self._generate_query_variants(query)
            logger.info(f"ğŸ”€ ìƒì„±ëœ ì¿¼ë¦¬ ë³€í˜•: {len(query_variants)}ê°œ")
            
            # 2. ê° ì¿¼ë¦¬ ë³€í˜•ìœ¼ë¡œ ê²€ìƒ‰
            all_candidates = {}  # IDë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
            
            # í•„í„° ì¡°ê±´
            where_condition = None
            if main_category_filter:
                where_condition = {"main_category": main_category_filter}
            
            # ë” ë§ì€ í›„ë³´ ê²€ìƒ‰ (top_k 20 â†’ search_limit 60+)
            search_limit = max(top_k * 3, 60)  # top_kê°€ 20ì´ë©´ 60ê°œ ê²€ìƒ‰
            
            for i, variant_query in enumerate(query_variants):
                logger.info(f"  ğŸ” ê²€ìƒ‰ {i+1}/{len(query_variants)}: '{variant_query[:30]}...'")
                
                query_embedding = self.model.encode([variant_query]).tolist()
                
                results = self.collection.query(
                    query_embeddings=query_embedding,
                    n_results=search_limit,
                    include=['documents', 'metadatas', 'distances'],
                    where=where_condition
                )
                
                # ê²°ê³¼ ì²˜ë¦¬ ë° í†µí•©
                if results['ids'] and len(results['ids'][0]) > 0:
                    for j in range(len(results['ids'][0])):
                        doc_id = results['ids'][0][j]
                        metadata = results['metadatas'][0][j]
                        distance = results['distances'][0][j]
                        
                        # ê¸°ë³¸ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
                        similarity_score = max(0, 1 - (distance / 2))
                        
                        # ì¿¼ë¦¬ ë³€í˜•ë³„ ê°€ì¤‘ì¹˜ (ì›ë³¸ ì¿¼ë¦¬ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
                        query_weight = 1.0 if i == 0 else 0.8  # ì›ë³¸ ì¿¼ë¦¬ê°€ ë” ì¤‘ìš”
                        weighted_score = similarity_score * query_weight
                        
                        # ê¸°ì¡´ ê²°ê³¼ì™€ ë³‘í•© (ìµœê³  ì ìˆ˜ ìœ ì§€)
                        if doc_id not in all_candidates:
                            all_candidates[doc_id] = {
                                'metadata': metadata,
                                'best_similarity': weighted_score,
                                'query_matches': [i],
                                'distances': [distance]
                            }
                        else:
                            # ë” ì¢‹ì€ ì ìˆ˜ë¡œ ì—…ë°ì´íŠ¸
                            if weighted_score > all_candidates[doc_id]['best_similarity']:
                                all_candidates[doc_id]['best_similarity'] = weighted_score
                            all_candidates[doc_id]['query_matches'].append(i)
                            all_candidates[doc_id]['distances'].append(distance)
            
            logger.info(f"  ğŸ“Š í†µí•©ëœ í›„ë³´: {len(all_candidates)}ê°œ")
            
            # 3. í–¥ìƒëœ ì¬ë­í‚¹
            enhanced_candidates = []
            
            for doc_id, candidate_data in all_candidates.items():
                metadata = candidate_data['metadata']
                best_similarity = candidate_data['best_similarity']
                query_matches = candidate_data['query_matches']
                
                question = metadata['question'].lower()
                answer = metadata['answer'].lower()
                query_lower = query.lower()
                chunk_type = metadata.get('chunk_type', 'qa_full')
                
                # í‚¤ì›Œë“œ ë§¤ì¹­ ë¶„ì„
                query_words = set(re.findall(r'\b[ê°€-í£]{2,}\b', query_lower))
                question_words = set(re.findall(r'\b[ê°€-í£]{2,}\b', question))
                answer_words = set(re.findall(r'\b[ê°€-í£]{2,}\b', answer))
                
                # ì§ˆë¬¸ ë§¤ì¹­ ì ìˆ˜
                question_match_count = len(query_words.intersection(question_words))
                question_match_ratio = question_match_count / max(len(query_words), 1)
                
                # ë‹µë³€ ë§¤ì¹­ ì ìˆ˜
                answer_match_count = len(query_words.intersection(answer_words))
                answer_match_ratio = answer_match_count / max(len(query_words), 1)
                
                # ì²­í¬ íƒ€ì…ë³„ ê°€ì¤‘ì¹˜
                chunk_weights = {
                    'qa_full': 1.0,
                    'question_focused': 0.9,
                    'answer_focused': 0.8,
                    'sentence_level': 0.7
                }
                chunk_weight = chunk_weights.get(chunk_type, 0.5)
                
                # ë‹¤ì¤‘ ì¿¼ë¦¬ ë§¤ì¹­ ë³´ë„ˆìŠ¤
                multi_query_bonus = len(set(query_matches)) * 0.1  # ì—¬ëŸ¬ ì¿¼ë¦¬ì—ì„œ ë°œê²¬ëœ ê²½ìš° ë³´ë„ˆìŠ¤
                
                # í‚¤ì›Œë“œ ë§¤ì¹­ ë³´ë„ˆìŠ¤
                keyword_bonus = (question_match_ratio * 0.4) + (answer_match_ratio * 0.3)
                
                # ìµœì¢… ì ìˆ˜ ê³„ì‚°
                final_score = min(1.0, (best_similarity * chunk_weight) + keyword_bonus + multi_query_bonus)
                
                if final_score >= min_relevance_score:
                    enhanced_candidates.append({
                        'main_category': metadata['main_category'],
                        'sub_category': metadata['sub_category'],
                        'question': metadata['question'],
                        'answer': metadata['answer'],
                        'source_file': metadata['source_file'],
                        'chunk_type': chunk_type,
                        'score': final_score,
                        'similarity_score': best_similarity,
                        'keyword_bonus': keyword_bonus,
                        'multi_query_bonus': multi_query_bonus,
                        'chunk_weight': chunk_weight,
                        'query_matches': len(set(query_matches))
                    })
            
            # 4. ì ìˆ˜ ê¸°ë°˜ ì •ë ¬ ë° ë‹¤ì–‘ì„± í™•ë³´
            enhanced_candidates.sort(key=lambda x: x['score'], reverse=True)
            
            # 5. ë‹¤ì–‘ì„±ì„ ìœ„í•œ ì¤‘ë³µ ì œê±° (ê°™ì€ ì§ˆë¬¸ì˜ ë‹¤ë¥¸ ì²­í¬ íƒ€ì… ì²˜ë¦¬)
            seen_questions = set()
            diverse_results = []
            
            for candidate in enhanced_candidates:
                question = candidate['question']
                
                # ìƒˆë¡œìš´ ì§ˆë¬¸ì´ê±°ë‚˜, ê¸°ì¡´ ì§ˆë¬¸ì´ì§€ë§Œ chunk_typeì´ qa_fullì¸ ê²½ìš° ìš°ì„ 
                if question not in seen_questions:
                    diverse_results.append(candidate)
                    seen_questions.add(question)
                elif candidate['chunk_type'] == 'qa_full' and len(diverse_results) < top_k:
                    # ê¸°ì¡´ ê²°ê³¼ì—ì„œ ê°™ì€ ì§ˆë¬¸ì˜ ë‹¤ë¥¸ ì²­í¬ë¥¼ qa_fullë¡œ êµì²´
                    for i, existing in enumerate(diverse_results):
                        if existing['question'] == question and existing['chunk_type'] != 'qa_full':
                            diverse_results[i] = candidate
                            break
                
                if len(diverse_results) >= top_k:
                    break
            
            # ìµœì¢… ê²°ê³¼ ì •ë¦¬
            final_results = diverse_results[:top_k]
            
            # ë­í¬ í• ë‹¹
            for i, result in enumerate(final_results):
                result['rank'] = i + 1
            
            logger.info(f"âœ… í–¥ìƒëœ ê²€ìƒ‰ ì™„ë£Œ: {len(final_results)}ê°œ ê²°ê³¼ (í›„ë³´ {len(enhanced_candidates)}ê°œì—ì„œ ì„ ë³„)")
            
            return final_results
            
        except Exception as e:
            logger.error(f"âŒ í–¥ìƒëœ ê²€ìƒ‰ ì‹¤íŒ¨: {e}", exc_info=True)
            return []
    
    def search(self, query: str, top_k: int = 20, main_category_filter: str = None, min_relevance_score: float = 0.3) -> List[Dict[str, Any]]:
        """ê¸°ë³¸ ê²€ìƒ‰ ë©”ì„œë“œ - í–¥ìƒëœ ê²€ìƒ‰ìœ¼ë¡œ ìœ„ì„ (í™•ì¥ëœ ì •ë³´ëŸ‰)"""
        return self.search_with_enhanced_retrieval(query, top_k, main_category_filter, min_relevance_score)
    
    def combine_contexts_with_history(self, current_context: List[Dict[str, Any]], conversation_history: List[Dict[str, str]], max_total_context: int = 25) -> List[Dict[str, Any]]:
        """í˜„ì¬ ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ì™€ ì´ì „ ëŒ€í™”ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ê²°í•© - ëŒ€í­ í™•ì¥ëœ ì»¨í…ìŠ¤íŠ¸"""
        logger.info(f"ì»¨í…ìŠ¤íŠ¸ ê²°í•©: í˜„ì¬ {len(current_context)}ê°œ, ì´ì „ ëŒ€í™” {len(conversation_history)}ê°œ, ìµœëŒ€ {max_total_context}ê°œ")
        try:
            # ì´ì „ ëŒ€í™”ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
            previous_contexts = []
            if conversation_history:
                for msg in conversation_history:
                    if msg.get('role') == 'assistant' and msg.get('context'):
                        previous_contexts.extend(msg['context'])
            
            # ì¤‘ë³µ ì œê±° (ì§ˆë¬¸ ê¸°ì¤€)
            seen_questions = set()
            unique_contexts = []
            
            # 1. í˜„ì¬ ê²€ìƒ‰ ê²°ê³¼ ìš°ì„  ì¶”ê°€
            for ctx in current_context:
                question = ctx.get('question', '')
                if question and question not in seen_questions:
                    seen_questions.add(question)
                    ctx_copy = ctx.copy()
                    ctx_copy['source_type'] = 'current'
                    unique_contexts.append(ctx_copy)
            
            # 2. ì´ì „ ì»¨í…ìŠ¤íŠ¸ ì¤‘ ê´€ë ¨ì„± ë†’ì€ ê²ƒë§Œ ì¶”ê°€ (ì„ê³„ê°’ ë‚®ì¶¤)
            remaining_slots = max_total_context - len(unique_contexts)
            if remaining_slots > 0:
                # ì´ì „ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
                previous_sorted = sorted(
                    previous_contexts, 
                    key=lambda x: x.get('score', 0), 
                    reverse=True
                )
                
                for ctx in previous_sorted:
                    if len(unique_contexts) >= max_total_context:
                        break
                    
                    question = ctx.get('question', '')
                    # ê´€ë ¨ì„± ì„ê³„ê°’ì„ ë‚®ì¶°ì„œ ë” ë§ì€ ì´ì „ ì»¨í…ìŠ¤íŠ¸ í¬í•¨ (0.4 â†’ 0.25)
                    if question and question not in seen_questions and ctx.get('score', 0) >= 0.25:
                        seen_questions.add(question)
                        ctx_copy = ctx.copy()
                        # ì´ì „ ì»¨í…ìŠ¤íŠ¸ì˜ ì ìˆ˜ë¥¼ ì•½ê°„ ë‚®ì¶°ì„œ í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ë³´ë‹¤ ìš°ì„ ìˆœìœ„ê°€ ë‚®ë„ë¡ ì¡°ì •
                        ctx_copy['score'] = ctx_copy.get('score', 0) * 0.85 
                        ctx_copy['source_type'] = 'previous'
                        unique_contexts.append(ctx_copy)
            
            # ìµœì¢… ì •ë ¬
            unique_contexts.sort(key=lambda x: (x.get('source_type') == 'current', x.get('score', 0)), reverse=True)
            
            logger.info(f"âœ… ì»¨í…ìŠ¤íŠ¸ ê²°í•© ì™„ë£Œ: {len(unique_contexts)}ê°œ (í˜„ì¬: {len(current_context)}, ì´ì „ ì¶”ê°€: {len(unique_contexts) - len(current_context)})")
            
            return unique_contexts
            
        except Exception as e:
            logger.error(f"âŒ ì»¨í…ìŠ¤íŠ¸ ê²°í•© ì‹¤íŒ¨: {e}", exc_info=True)
            return current_context
    
    def get_categories(self) -> Dict[str, Any]:
        """ì „ì²´ ì¹´í…Œê³ ë¦¬ ì •ë³´ ë°˜í™˜"""
        if not hasattr(self, 'main_categories'):
            logger.warning("âš ï¸ ì¹´í…Œê³ ë¦¬ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {'main_categories': {}, 'total_main_categories': 0, 'total_regulations': 0}
        
        return {
            'main_categories': self.main_categories,
            'total_main_categories': len(self.main_categories),
            'total_regulations': len(self.regulations_data) if hasattr(self, 'regulations_data') else 0
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """ì¸ë±ìŠ¤ í†µê³„ ì •ë³´ ë°˜í™˜"""
        try:
            count = self.collection.count()
            main_cats = self.main_categories if hasattr(self, 'main_categories') else {}
            
            # ì²­í‚¹ í†µê³„
            chunk_stats = {}
            if hasattr(self, 'regulations_data'):
                for item in self.regulations_data:
                    chunk_type = item.get('chunk_type', 'unknown')
                    chunk_stats[chunk_type] = chunk_stats.get(chunk_type, 0) + 1
            
            return {
                'total_documents': count,
                'collection_name': self.collection.name,
                'persist_directory': self.persist_directory,
                'is_ready': count > 0,
                'main_categories': main_cats,
                'total_main_categories': len(main_cats),
                'chunk_statistics': chunk_stats,
                'enhanced_features': [
                    'ë‹¤ì¤‘ ì¿¼ë¦¬ ê²€ìƒ‰',
                    'í–¥ìƒëœ ì²­í‚¹ ì „ëµ',
                    'í•˜ì´ë¸Œë¦¬ë“œ ì¬ë­í‚¹',
                    'ëŒ€í­ í™•ì¥ëœ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° (25ê°œ)',
                    'ë‹¤ì–‘ì„± ë³´ì¥ ì•Œê³ ë¦¬ì¦˜',
                    '2.5ë°° í™•ì¥ëœ ê²€ìƒ‰ ë²”ìœ„ (20ê°œ)'
                ]
            }
        except Exception as e:
            logger.error(f"âŒ í†µê³„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
            return {'total_documents': 0, 'is_ready': False, 'main_categories': {}, 'total_main_categories': 0}
    
    def rebuild_index(self):
        """ì¸ë±ìŠ¤ ì™„ì „ ì¬êµ¬ì¶• (ê°œì„ ëœ ì˜¤ë¥˜ ì²˜ë¦¬)"""
        logger.info("ChromaDB ì¸ë±ìŠ¤ ì™„ì „ ì¬êµ¬ì¶• ì‹œì‘")
        try:
            current_collection_name = getattr(self.collection, 'name', 'company_regulations')
            
            # ì•ˆì „í•œ ì»¬ë ‰ì…˜ ì¬ìƒì„±
            try:
                logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ ì»¬ë ‰ì…˜ '{current_collection_name}' ì‚­ì œ ì¤‘...")
                self.chroma_client.delete_collection(name=current_collection_name)
                logger.info("âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ ì™„ë£Œ")
            except Exception as delete_error:
                logger.warning(f"âš ï¸ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ ì‹¤íŒ¨ (ì´ë¯¸ ì—†ì„ ìˆ˜ ìˆìŒ): {delete_error}")
            
            # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
            try:
                logger.info("â• ìƒˆ ì»¬ë ‰ì…˜ ìƒì„± ì¤‘...")
                self.collection = self.chroma_client.create_collection(
                    name="company_regulations",
                    metadata={"description": "í–¥ìƒëœ íšŒì‚¬ ì „ì²´ ë‚´ê·œ ë²¡í„° ê²€ìƒ‰ ì»¬ë ‰ì…˜"}
                )
                logger.info("âœ… ìƒˆ ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ")
            except Exception as create_error:
                logger.error(f"âŒ ìƒˆ ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {create_error}")
                
                # ëŒ€ì•ˆ: ìƒˆë¡œìš´ ì´ë¦„ìœ¼ë¡œ ì»¬ë ‰ì…˜ ìƒì„±
                import time
                backup_name = f"company_regulations_backup_{int(time.time())}"
                logger.info(f"ğŸ”„ ëŒ€ì•ˆ: '{backup_name}' ì´ë¦„ìœ¼ë¡œ ì»¬ë ‰ì…˜ ìƒì„±...")
                
                try:
                    self.collection = self.chroma_client.create_collection(
                        name=backup_name,
                        metadata={"description": "í–¥ìƒëœ íšŒì‚¬ ì „ì²´ ë‚´ê·œ ë²¡í„° ê²€ìƒ‰ ì»¬ë ‰ì…˜ (ë°±ì—…)"}
                    )
                    logger.info(f"âœ… ë°±ì—… ì»¬ë ‰ì…˜ '{backup_name}' ìƒì„± ì™„ë£Œ")
                except Exception as backup_error:
                    logger.error(f"âŒ ë°±ì—… ì»¬ë ‰ì…˜ ìƒì„±ë„ ì‹¤íŒ¨: {backup_error}")
                    return False
            
            return self.build_index()
            
        except Exception as e:
            logger.error(f"âŒ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì‹¤íŒ¨: {e}", exc_info=True)
            return False

class LLMClient:
    def __init__(self, api_url: str = "http://localhost:1234/v1/chat/completions"):
        """LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        self.api_url = api_url
        logger.info(f"LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”: API URL = {self.api_url}")
    
    def _create_enhanced_system_prompt(self, context: List[Dict[str, Any]], conversation_history: List[Dict[str, str]] = None) -> str:
        """ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ì„ í™œìš©í•˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„ (í™•ì¥ëœ ê¸°ì¤€)
        high_quality = [c for c in context if c.get('score', 0) >= 0.7]
        medium_quality = [c for c in context if 0.5 <= c.get('score', 0) < 0.7]
        low_quality = [c for c in context if 0.25 <= c.get('score', 0) < 0.5]
        
        # ê¸°ë³¸ ì—­í•  ì •ì˜ (ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ ê°•ì¡°)
        system_prompt = f"""ë‹¹ì‹ ì€ ìš°ë¦¬ íšŒì‚¬ì˜ ë‚´ê·œë¥¼ ì •í™•íˆ ì•„ëŠ” ì¹œê·¼í•œ ë™ë£Œì…ë‹ˆë‹¤. ì§ì›ë“¤ì˜ ê¶ê¸ˆí•œ ì ì„ ìì—°ìŠ¤ëŸ½ì§€ë§Œ ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ğŸ¯ í•µì‹¬ ì›ì¹™ (ì ˆëŒ€ ì¤€ìˆ˜):
â€¢ **ëŒ€í­ í™•ì¥ëœ ì •ë³´ í™œìš©**: ì œê³µëœ {len(context)}ê°œì˜ ë‹¤ì–‘í•œ ë‚´ê·œ ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì™„ì „í•œ ë‹µë³€ ì œê³µ
â€¢ **ë‚´ê·œ ê¸°ë°˜ ë‹µë³€ í•„ìˆ˜**: ë°˜ë“œì‹œ ì œê³µëœ ë‚´ê·œ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
â€¢ **ì¶”ì¸¡ ê¸ˆì§€**: ë‚´ê·œì— ëª…ì‹œë˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”
â€¢ **ë‹¤ê°ë„ ê²€í† **: ì—¬ëŸ¬ ê´€ë ¨ ë‚´ê·œê°€ ìˆì„ ë•ŒëŠ” ëª¨ë‘ ê²€í† í•˜ì—¬ í¬ê´„ì  ë‹µë³€ ì œê³µ
â€¢ **ì •ë³´ ì¢…í•© ëŠ¥ë ¥**: ê´€ë ¨ëœ ì—¬ëŸ¬ ê·œì •ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ì—¬ ì„¤ëª…
â€¢ **ë¶ˆí™•ì‹¤ì‹œ ëª…ì‹œ**: ê´€ë ¨ ë‚´ê·œê°€ ì—†ê±°ë‚˜ ë¶ˆë¶„ëª…í•˜ë©´ "ë‚´ê·œì—ì„œ í™•ì¸ì´ ì–´ë ¤ì›Œìš”"ë¼ê³  ëª…í™•íˆ ë§í•˜ì„¸ìš”
â€¢ **ë‹´ë‹¹ ë¶€ì„œ ë° ë¬¸ì˜ ì•ˆë‚´**: ì •í™•í•œ ë‹µë³€ì´ ì–´ë ¤ìš¸ ë•ŒëŠ” ê²½ì˜ì§€ì›íŒ€ ë˜ëŠ” ê°ì‚¬íŒ€ ë¬¸ì˜ ì•ˆë‚´í•˜ê³  ê·¸ì™¸ì˜ íŒ€ ë˜ëŠ” ë¶€ì„œëŠ” ë‹µë³€í•˜ì§€ ë§ê²ƒ
â€¢ **ì—°ì°¨, íœ´ê°€ ê³„ì‚°**: ì—°ì°¨ì¼ìˆ˜ = min(ê¸°ë³¸ì—°ì°¨ì¼ìˆ˜ + âŒŠ (ê·¼ì†ì—°ìˆ˜(ë…„) âˆ’ 1) Ã· 2 âŒ‹, 25)

ğŸ’¬ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ë°©ì‹:
â€¢ ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ì„¤ëª…í•˜ë˜, ë‚´ê·œ ë‚´ìš©ì€ ì •í™•íˆ ì „ë‹¬
â€¢ ì—¬ëŸ¬ ê´€ë ¨ ì •ë³´ê°€ ìˆì„ ë•ŒëŠ” "ë‚´ê·œë¥¼ ë³´ë‹ˆê¹Œìš”", "ì¶”ê°€ë¡œ í™•ì¸í•´ë³´ë‹ˆê¹Œìš”", "ê´€ë ¨í•´ì„œ ë˜ ë‹¤ë¥¸ ê·œì •ë„ ìˆì–´ìš”" ë“± ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
â€¢ ë³µì¡í•œ ë‚´ìš©ì€ "ì‰½ê²Œ ë§í•˜ë©´", "ì •ë¦¬í•˜ë©´", "í•µì‹¬ë§Œ ë§ì”€ë“œë¦¬ë©´" ë“±ìœ¼ë¡œ í’€ì–´ì„œ ì„¤ëª…
â€¢ ì´ì „ ëŒ€í™”ì™€ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ë˜, ë‚´ê·œ ë²”ìœ„ ë‚´ì—ì„œë§Œ
â€¢ í’ë¶€í•œ ì •ë³´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ ì „ë‹¬

ğŸ“‹ ë‹µë³€ ë°©ì‹ (í™•ì¥ëœ ì •ë³´ëŸ‰ ê¸°ë°˜):
â€¢ ë‚´ê·œì— ëª…í™•í•œ ë‹µì´ ìˆìœ¼ë©´ â†’ ëª¨ë“  ê´€ë ¨ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì™„ì „í•˜ê³  ì²´ê³„ì ì¸ ì„¤ëª…
â€¢ ì—¬ëŸ¬ ê·œì •ì´ ê´€ë ¨ë˜ë©´ â†’ ê°ê°ì„ êµ¬ë¶„í•´ì„œ ì •ë¦¬í•˜ë˜, ì—°ê´€ì„±ê³¼ ìš°ì„ ìˆœìœ„ë„ ì„¤ëª…
â€¢ ë¶€ë¶„ì ìœ¼ë¡œë§Œ ê´€ë ¨ëœ ì •ë³´ê°€ ìˆìœ¼ë©´ â†’ í™•ì‹¤í•œ ë¶€ë¶„ê³¼ ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì„ ëª…í™•íˆ êµ¬ë¶„
â€¢ ë‹¤ì–‘í•œ ì‚¬ë¡€ë‚˜ ìƒí™©ì´ ìˆìœ¼ë©´ â†’ ê° ê²½ìš°ë³„ë¡œ ë‚˜ëˆ„ì–´ ì„¤ëª…
â€¢ ë‚´ê·œê°€ ì• ë§¤í•˜ê±°ë‚˜ ì—†ìœ¼ë©´ â†’ "ë‚´ê·œì—ì„œëŠ” êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œë˜ì–´ ìˆì§€ ì•Šì•„ìš”" + ë‹´ë‹¹ ë¶€ì„œ ì•ˆë‚´
â€¢ ì ˆëŒ€ ë‚´ê·œì— ì—†ëŠ” ë‚´ìš©ì„ ì¶”ê°€í•˜ê±°ë‚˜ ì„ì˜ë¡œ í•´ì„í•˜ì§€ ì•Šê¸°"""

        # ëŒ€í­ í™•ì¥ëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
        if context:
            system_prompt += f"\n\nğŸ“š ì°¸ê³ í•  ë‚´ê·œ ì •ë³´ (ëŒ€í­ í™•ì¥ëœ ì¢…í•© ë¶„ì„ - ì´ {len(context)}ê°œ):\n"
            
            # í˜„ì¬ ê²€ìƒ‰ ê²°ê³¼
            current_contexts = [c for c in context if c.get('source_type') == 'current']
            if current_contexts:
                system_prompt += f"\n[ì´ë²ˆ ì§ˆë¬¸ ê´€ë ¨ ë‚´ê·œ - í™•ì¥ëœ ë‹¤ê°ë„ ê²€ìƒ‰ ê²°ê³¼: {len(current_contexts)}ê°œ]\n"
                for i, item in enumerate(current_contexts, 1):
                    score = item.get('score', 0)
                    chunk_type = item.get('chunk_type', 'qa_full')
                    query_matches = item.get('query_matches', 1)
                    
                    relevance = "ë§¤ìš° ê´€ë ¨ ë†’ìŒ" if score >= 0.8 else "ê´€ë ¨ ë†’ìŒ" if score >= 0.6 else "ê´€ë ¨ ìˆìŒ" if score >= 0.4 else "ë¶€ë¶„ ê´€ë ¨"
                    
                    system_prompt += f"{i}. [{item.get('main_category', 'N/A')} > {item.get('sub_category', 'N/A')}]\n"
                    system_prompt += f"   Q: {item.get('question', 'N/A')}\n"
                    system_prompt += f"   A: {item.get('answer', 'N/A')}\n"
                    system_prompt += f"   (ê´€ë ¨ë„: {relevance}, íƒ€ì…: {chunk_type}, ë§¤ì¹­: {query_matches}ê°œ ì¿¼ë¦¬)\n\n"
                
                system_prompt += f"ğŸ’¡ ì´ {len(current_contexts)}ê°œì˜ ê´€ë ¨ ë‚´ê·œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ê²€í† í•˜ì—¬ ì™„ì „í•˜ê³  ì²´ê³„ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\n"
            
            # ì´ì „ ëŒ€í™” ê´€ë ¨ ë‚´ê·œ
            previous_contexts = [c for c in context if c.get('source_type') == 'previous']
            if previous_contexts:
                system_prompt += f"\n[ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ê´€ë ¨ ë‚´ê·œ: {len(previous_contexts)}ê°œ]\n"
                for i, item in enumerate(previous_contexts, len(current_contexts) + 1):
                    score = item.get('score', 0)
                    relevance = "ë§¤ìš° ê´€ë ¨ ë†’ìŒ" if score >= 0.8 else "ê´€ë ¨ ë†’ìŒ" if score >= 0.6 else "ê´€ë ¨ ìˆìŒ"
                    system_prompt += f"{i}. [{item.get('main_category', 'N/A')} > {item.get('sub_category', 'N/A')}]\n"
                    system_prompt += f"   Q: {item.get('question', 'N/A')}\n"
                    system_prompt += f"   A: {item.get('answer', 'N/A')}\n"
                    system_prompt += f"   (ê´€ë ¨ë„: {relevance}, ì´ì „ ëŒ€í™”)\n\n"
            
            # ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆì— ë”°ë¥¸ ì •í™•í•œ ì•ˆë‚´ (í™•ì¥ëœ ê¸°ì¤€)
            if len(high_quality) == 0 and len(medium_quality) == 0:
                system_prompt += "\nâš ï¸ ì¤‘ìš”: ì´ë²ˆ ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ëœ ë‚´ê·œë¥¼ ì°¾ê¸° ì–´ë ¤ì› ìŠµë‹ˆë‹¤. ë¶€ë¶„ì ìœ¼ë¡œ ê´€ë ¨ëœ ì •ë³´ë§Œ ìˆìœ¼ë¯€ë¡œ, í™•ì‹¤í•œ ë¶€ë¶„ë§Œ ë‹µë³€í•˜ê³  ë¶ˆë¶„ëª…í•œ ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ë©°, ë‹´ë‹¹ ë¶€ì„œ ë¬¸ì˜ë¥¼ ì•ˆë‚´í•˜ì„¸ìš”.\n"
            elif len(high_quality) == 0:
                system_prompt += f"\nğŸ’¡ ì£¼ì˜: ê´€ë ¨ì„±ì´ ë³´í†µì¸ ë‚´ê·œë“¤ì´ {len(medium_quality)}ê°œ ìˆìŠµë‹ˆë‹¤. ì´ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ê²€í† í•˜ë˜, í™•ì‹¤í•œ ë¶€ë¶„ë§Œ ë‹µë³€í•˜ê³ , ë¶ˆë¶„ëª…í•œ ë‚´ìš©ì€ 'ë‚´ê·œì—ì„œ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œë˜ì–´ ìˆì§€ ì•Šë‹¤'ê³  ëª…í™•íˆ í‘œí˜„í•˜ì„¸ìš”.\n"
            else:
                system_prompt += f"\nâœ… ìš°ìˆ˜: ê´€ë ¨ì„±ì´ ë†’ì€ ë‚´ê·œ {len(high_quality)}ê°œë¥¼ í¬í•¨í•˜ì—¬ ì´ {len(context)}ê°œì˜ í’ë¶€í•œ ì •ë³´ë¥¼ ì œê³µë°›ì•˜ìŠµë‹ˆë‹¤. ì´ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì™„ì „í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\n"
                
            # ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ì— ëŒ€í•œ íŠ¹ë³„ ì•ˆë‚´
            if len(context) >= 20:
                system_prompt += f"\nğŸš€ íŠ¹ë³„ ì•ˆë‚´: ì´ë²ˆì—ëŠ” {len(context)}ê°œì˜ ë§¤ìš° í’ë¶€í•œ ì •ë³´ê°€ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë“  ì •ë³´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê²€í† í•˜ì—¬ ê°€ëŠ¥í•œ í•œ ì™„ì „í•˜ê³  í¬ê´„ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”. ê´€ë ¨ëœ ì—¬ëŸ¬ ê·œì •ì´ ìˆë‹¤ë©´ ìš°ì„ ìˆœìœ„ì™€ ì—°ê´€ì„±ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n"
        
        # ì´ì „ ëŒ€í™” ë§¥ë½ ì¶”ê°€
        if conversation_history and len(conversation_history) > 0:
            system_prompt += "\n\nğŸ’¬ ì´ì „ ëŒ€í™” ë§¥ë½:\n"
            recent_history = conversation_history[-3:] 
            for msg in recent_history:
                role = "ì§ì›" if msg.get('role') == 'user' else "ë‚˜"
                content = msg.get('content', '')
                truncated_content = content[:150] + ('...' if len(content) > 150 else '')
                system_prompt += f"â€¢ {role}: {truncated_content}\n"
            system_prompt += "\nìœ„ ëŒ€í™”ì™€ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n"
        
        system_prompt += "\n\nğŸ“ ì¶”ê°€ ë¬¸ì˜ì²˜:\nâ€¢ ê²½ì˜ì§€ì›íŒ€: ì¸ì‚¬, ê¸‰ì—¬, ë³µë¦¬í›„ìƒ, ì´ë¬´, ì¬ë¬´, íšŒê³„ ê´€ë ¨\nâ€¢ ê°ì‚¬íŒ€: ë²•ì  íŒë‹¨, ì»´í”Œë¼ì´ì–¸ìŠ¤, ê·œì • í•´ì„ ê´€ë ¨"
        
        return system_prompt
    
    def generate_response_stream_with_history(self, query: str, context: List[Dict[str, Any]], conversation_history: List[Dict[str, str]] = None):
        """ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ì„ í™œìš©í•œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±"""
        logger.info(f"ğŸ“ ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±: '{query[:50]}...' (ì»¨í…ìŠ¤íŠ¸: {len(context)}ê°œ)")
        
        try:
            # ëŒ€í­ í™•ì¥ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_content = self._create_enhanced_system_prompt(context, conversation_history)
            
            messages = [{"role": "system", "content": system_content}]
            
            # ì´ì „ ëŒ€í™” ì¶”ê°€ (ìµœê·¼ 2-3ê°œë§Œ)
            if conversation_history:
                recent_history_for_api = conversation_history[-2:] if len(conversation_history) > 2 else conversation_history
                for msg in recent_history_for_api:
                    if msg.get('role') in ['user', 'assistant']:
                        messages.append({
                            "role": msg['role'],
                            "content": msg['content']
                        })
            
            messages.append({"role": "user", "content": query})
            
            # LLM API í˜¸ì¶œ - ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ ì²˜ë¦¬ ì„¤ì •
            response = requests.post(
                self.api_url,
                json={
                    "model": "qwen3-30b-a3b-mlx",
                    "messages": messages,
                    "temperature": 0.1,  # ì •í™•ì„± ìš°ì„ 
                    "max_tokens": 3000,  # 2500 â†’ 3000ìœ¼ë¡œ í™•ì¥ (ë” ë§ì€ ì •ë³´ ì²˜ë¦¬)
                    "top_p": 0.85,
                    "frequency_penalty": 0.1,
                    "presence_penalty": 0.05,
                    "stream": True
                },
                timeout=150,  # 120ì´ˆ â†’ 150ì´ˆ (ë” ë§ì€ ì •ë³´ ì²˜ë¦¬ ì‹œê°„)
                stream=True
            )
            
            if response.status_code == 200:
                accumulated_response = ""
                for line in response.iter_lines():
                    if line:
                        line_text = line.decode('utf-8')
                        if line_text.startswith('data: '):
                            data_str = line_text[6:]
                            
                            if data_str.strip() == '[DONE]':
                                logger.info(f"âœ… ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì™„ë£Œ")
                                yield {"type": "done", "content": ""}
                                break
                                
                            try:
                                data = json.loads(data_str)
                                delta = data['choices'][0]['delta']
                                
                                if 'content' in delta:
                                    chunk_content = delta['content']
                                    accumulated_response += chunk_content
                                    yield {"type": "content", "content": chunk_content}
                                
                            except json.JSONDecodeError:
                                continue
                            except (KeyError, IndexError):
                                continue
                
                # ì‘ë‹µ ì™„ë£Œ ì²˜ë¦¬
                if accumulated_response and len(accumulated_response) >= 2500:
                    warning_msg = "\n\nğŸ’¬ ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë‹¤ì‹œ ë¬¼ì–´ë³´ì„¸ìš”!"
                    yield {"type": "warning", "content": warning_msg}
                yield {"type": "done", "content": ""}
            else:
                error_msg = "ì£„ì†¡í•´ìš”, ì§€ê¸ˆ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ìˆëŠ” ê²ƒ ê°™ì•„ìš”. ì ì‹œ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                yield {"type": "error", "content": error_msg}
                
        except requests.exceptions.Timeout:
            error_msg = "ëŒ€í­ í™•ì¥ëœ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ì‹œê°„ì´ ê±¸ë¦¬ê³  ìˆì–´ìš”. ì ì‹œ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            yield {"type": "error", "content": error_msg}
        except Exception as e:
            logger.error(f"âŒ ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            error_msg = "ì£„ì†¡í•´ìš”, ë‹µë³€ì„ ë§Œë“œëŠ” ì¤‘ì— ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            yield {"type": "error", "content": error_msg}

    def generate_response_with_history(self, query: str, context: List[Dict[str, Any]], conversation_history: List[Dict[str, str]] = None) -> str:
        """ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ì„ í™œìš©í•œ ë¹„ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±"""
        logger.info(f"ğŸ“ ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ ê¸°ë°˜ ì‘ë‹µ ìƒì„±: '{query[:50]}...' (ì»¨í…ìŠ¤íŠ¸: {len(context)}ê°œ)")

        try:
            # ëŒ€í­ í™•ì¥ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_content = self._create_enhanced_system_prompt(context, conversation_history)
            
            messages = [{"role": "system", "content": system_content}]
            
            # ì´ì „ ëŒ€í™” ì¶”ê°€
            if conversation_history:
                recent_history = conversation_history[-2:] if len(conversation_history) > 2 else conversation_history
                for msg in recent_history:
                    if msg.get('role') in ['user', 'assistant']:
                        messages.append({
                            "role": msg['role'],
                            "content": msg['content']
                        })
            
            messages.append({"role": "user", "content": query})

            # LLM API í˜¸ì¶œ - ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ ì²˜ë¦¬
            response = requests.post(
                self.api_url,
                json={
                    "model": "qwen3-30b-a3b-mlx",
                    "messages": messages,
                    "temperature": 0.1,  # ì •í™•ì„± ìš°ì„ 
                    "max_tokens": 3000,  # 2500 â†’ 3000ìœ¼ë¡œ í™•ì¥
                    "top_p": 0.85,
                    "frequency_penalty": 0.1,
                    "presence_penalty": 0.05,
                    "stream": True
                },
                timeout=150,  # 120ì´ˆ â†’ 150ì´ˆ
                stream=True
            )
            
            if response.status_code == 200:
                generated_text = ""
                
                for line in response.iter_lines():
                    if line:
                        line_text = line.decode('utf-8')
                        if line_text.startswith('data: '):
                            data_str = line_text[6:]
                            
                            if data_str.strip() == '[DONE]':
                                break
                                
                            try:
                                data = json.loads(data_str)
                                delta = data['choices'][0]['delta']
                                
                                if 'content' in delta:
                                    generated_text += delta['content']
                                
                                if 'finish_reason' in data['choices'][0]:
                                    break
                                    
                            except json.JSONDecodeError:
                                continue
                            except (KeyError, IndexError):
                                continue
                
                if not generated_text.strip():
                    return "ì£„ì†¡í•´ìš”, ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                
                logger.info(f"âœ… ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ ê¸°ë°˜ ì‘ë‹µ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(generated_text)}ì)")
                return generated_text
            else:
                return "ì£„ì†¡í•´ìš”, ì§€ê¸ˆ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ìˆëŠ” ê²ƒ ê°™ì•„ìš”. ì ì‹œ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                
        except requests.exceptions.Timeout:
            return "ëŒ€í­ í™•ì¥ëœ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ì‹œê°„ì´ ê±¸ë¦¬ê³  ìˆì–´ìš”. ì ì‹œ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        except Exception as e:
            logger.error(f"âŒ ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ ê¸°ë°˜ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            return "ì£„ì†¡í•´ìš”, ë‹µë³€ì„ ë§Œë“œëŠ” ì¤‘ì— ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

# FastAPI ì•± ì„¤ì •
app = FastAPI(
    title="ëŒ€í­ í™•ì¥ëœ íšŒì‚¬ ë‚´ê·œ RAG ì‹œìŠ¤í…œ",
    description="""
    **FastAPI ê¸°ë°˜ ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ íšŒì‚¬ ë‚´ê·œ RAG ì‹œìŠ¤í…œ**
    
    ## ì£¼ìš” íŠ¹ì§•
    - ğŸ” ë‹¤ì¤‘ ì¿¼ë¦¬ ê²€ìƒ‰ (ì›ë³¸ + ë³€í˜• ì¿¼ë¦¬ë¡œ ë‹¤ê°ë„ ê²€ìƒ‰)
    - ğŸ“ í–¥ìƒëœ ì²­í‚¹ ì „ëµ (QA + ì§ˆë¬¸ + ë‹µë³€ + ë¬¸ì¥ ë‹¨ìœ„)
    - ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ ì¬ë­í‚¹ (ë²¡í„° + í‚¤ì›Œë“œ + ë‹¤ì¤‘ì¿¼ë¦¬ ë§¤ì¹­)
    - ğŸ“Š ëŒ€í­ í™•ì¥ëœ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° (ìµœëŒ€ 25ê°œ â†’ í›¨ì”¬ ë” í’ë¶€í•œ ì •ë³´)
    - ğŸŒŸ ë‹¤ì–‘ì„± ë³´ì¥ ì•Œê³ ë¦¬ì¦˜ (ì¤‘ë³µ ì œê±° + í’ˆì§ˆ ìœ ì§€)
    - ğŸ“‰ ë‚®ì€ ê´€ë ¨ì„± ì„ê³„ê°’ (0.25, ë¶€ë¶„ ê´€ë ¨ ì •ë³´ë„ í¬í•¨)
    - ğŸ¯ ì •í™•ì„± ìµœìš°ì„  (Temperature: 0.1)
    - ğŸ“ ë” ê¸´ ì‘ë‹µ í—ˆìš© (2500 í† í°)
    
    ## ì„±ëŠ¥ ì§€í‘œ (ëŒ€í­ ê°œì„ )
    - **ê²€ìƒ‰ ë²”ìœ„**: top_k=20 (ê¸°ì¡´ 8ê°œ â†’ 20ê°œë¡œ 2.5ë°° í™•ì¥)
    - **ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°**: 25ê°œ (ê¸°ì¡´ 10ê°œ â†’ 25ê°œë¡œ 2.5ë°° í™•ì¥)
    - **ê²€ìƒ‰ í•œê³„**: 60ê°œ í›„ë³´ (ê¸°ì¡´ 25ê°œ â†’ 60ê°œë¡œ 2.4ë°° í™•ì¥)
    - **ìµœì†Œ ê´€ë ¨ì„±**: 0.25 (ë” ë§ì€ ì •ë³´ ìˆ˜ì§‘)
    - **ìµœëŒ€ í† í°**: 2500 (ì™„ì „í•œ ë‹µë³€ í—ˆìš©)
    - **Temperature**: 0.1 (ì •í™•ì„± ìš°ì„ )
    """,
    version="3.0.0",
    contact={
        "name": "RAG ì‹œìŠ¤í…œ ê°œë°œíŒ€",
        "email": "dev@company.com"
    }
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì „ì—­ ì˜ˆì™¸ ì²˜ë¦¬ê¸°
from fastapi import Request
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """ìš”ì²­ ê²€ì¦ ì˜¤ë¥˜ ì²˜ë¦¬"""
    logger.error(f"âŒ ìš”ì²­ ê²€ì¦ ì‹¤íŒ¨: {exc}")
    
    error_details = []
    for error in exc.errors():
        field = " -> ".join(str(loc) for loc in error["loc"])
        error_details.append({
            "field": field,
            "message": error["msg"],
            "type": error["type"]
        })
    
    return JSONResponse(
        status_code=422,
        content={
            "error": "ìš”ì²­ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨",
            "details": error_details,
            "help": {
                "message": "API ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì—¬ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ìš”ì²­í•´ì£¼ì„¸ìš”.",
                "docs_url": "/docs",
                "common_issues": [
                    "query í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì…ë‹ˆë‹¤.",
                    "conversation_history í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                    "top_k ê°’ì´ 1-50 ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.",
                    "POST ìš”ì²­ì‹œ Content-Type: application/jsonì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "í…ŒìŠ¤íŠ¸ìš© /test/simple_chat ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                ]
            }
        }
    )

@app.exception_handler(500)
async def internal_server_error_handler(request: Request, exc: Exception):
    """ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ ì²˜ë¦¬"""
    logger.error(f"âŒ ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "error": "ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "message": "ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
            "request_id": id(request)
        }
    )

# ì „ì—­ ê°ì²´ë“¤
rag_system: CompanyRegulationsRAGSystem = None
llm_client: LLMClient = None

def initialize_system():
    """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    global rag_system, llm_client
    
    if rag_system is not None and llm_client is not None:
        logger.info("ì‹œìŠ¤í…œì´ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        return

    logger.info("í–¥ìƒëœ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
    
    try:
        rag_system = CompanyRegulationsRAGSystem()
        llm_client = LLMClient()
        
        data_directory = "./data_json"
        
        if os.path.exists(data_directory):
            logger.info("íšŒì‚¬ ë‚´ê·œ ë°ì´í„° ë¡œë“œ ë° í–¥ìƒëœ ì¸ë±ìŠ¤ êµ¬ì¶•...")
            if rag_system.load_company_regulations_data(data_directory):
                if rag_system.build_index():
                    stats = rag_system.get_stats()
                    logger.info(f"âœ… í–¥ìƒëœ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ: {stats['total_documents']}ê°œ ì²­í¬")
                    logger.info(f"ğŸ“Š ì²­í‚¹ í†µê³„: {stats.get('chunk_statistics', {})}")
                else:
                    logger.error("âŒ ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨")
            else:
                logger.error("âŒ ë‚´ê·œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        else:
            logger.error(f"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ ì—†ìŒ: {data_directory}. ë°ì´í„° ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

    except Exception as e:
        logger.critical(f"ğŸ”¥ í–¥ìƒëœ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
        rag_system = None
        llm_client = None

@app.get("/health", response_model=HealthResponse, summary="ëŒ€í­ í™•ì¥ëœ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸", description="ëŒ€í­ í™•ì¥ëœ RAG ì‹œìŠ¤í…œì˜ ìƒíƒœì™€ í†µê³„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    if rag_system is None or llm_client is None:
        raise HTTPException(
            status_code=503,
            detail={
                "status": "initializing_or_error",
                "rag_ready": False,
                "regulations_count": 0,
                "main_categories_count": 0,
                "improvements": "ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰, 2.5ë°° ê²€ìƒ‰ ë²”ìœ„, ì •í™•ë„ ê°œì„ ",
                "message": "ëŒ€í­ í™•ì¥ëœ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ì´ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

    stats = rag_system.get_stats()
    
    status = "healthy" if stats['is_ready'] else "unhealthy"

    return HealthResponse(
        status=status,
        rag_ready=stats['is_ready'],
        regulations_count=stats['total_documents'],
        main_categories_count=stats.get('total_main_categories', 0),
        chunk_statistics=stats.get('chunk_statistics', {}),
        improvements="ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰, 2.5ë°° ê²€ìƒ‰ ë²”ìœ„, ì •í™•ë„ ê°œì„ ",
        enhanced_features=stats.get('enhanced_features', [])
    )

@app.get("/categories", summary="ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¡°íšŒ", description="ì „ì²´ ë‚´ê·œ ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
async def get_categories():
    """ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¡°íšŒ"""
    if not rag_system:
        raise HTTPException(status_code=503, detail="ëŒ€í­ í™•ì¥ëœ RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    categories_info = rag_system.get_categories()
    return {
        "categories": categories_info,
        "database": "ChromaDB (Massively Enhanced)",
        "system_type": "ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ íšŒì‚¬ ë‚´ê·œ ì‹œìŠ¤í…œ"
    }

@app.post("/search", response_model=SearchResponse, summary="ëŒ€í­ í™•ì¥ëœ ë‚´ê·œ ê²€ìƒ‰", description="ëŒ€í­ í™•ì¥ëœ ë‹¤ì¤‘ ì¿¼ë¦¬ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë‚´ê·œë¥¼ ì°¾ìŠµë‹ˆë‹¤.")
async def search_regulations(request: SearchRequest):
    """ëŒ€í­ í™•ì¥ëœ íšŒì‚¬ ë‚´ê·œ ê²€ìƒ‰"""
    if not rag_system:
        raise HTTPException(status_code=503, detail="ëŒ€í­ í™•ì¥ëœ RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ëŒ€í­ í™•ì¥ëœ ê²€ìƒ‰ ì‚¬ìš©
    results = rag_system.search_with_enhanced_retrieval(
        request.query, 
        request.top_k,  # ê¸°ë³¸ê°’ 20
        request.main_category_filter, 
        min_relevance_score=0.3
    )
    
    search_results = [SearchResult(**result) for result in results]
    
    return SearchResponse(
        query=request.query,
        results=search_results,
        count=len(results),
        main_category_filter=request.main_category_filter,
        search_type="ëŒ€í­ í™•ì¥ëœ ë‹¤ì¤‘ì¿¼ë¦¬ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰",
        min_relevance=0.3,
        enhanced_features=[
            "ë‹¤ì¤‘ ì¿¼ë¦¬ ë³€í˜•",
            "í–¥ìƒëœ ì²­í‚¹",
            "í•˜ì´ë¸Œë¦¬ë“œ ì¬ë­í‚¹",
            "ë‹¤ì–‘ì„± ë³´ì¥",
            f"2.5ë°° í™•ì¥ëœ ê²€ìƒ‰ ë²”ìœ„ (ìµœëŒ€ {request.top_k}ê°œ)"
        ]
    )

@app.post("/chat", response_model=ChatResponse, summary="í–¥ìƒëœ ë‚´ê·œ ìƒë‹´", description="í–¥ìƒëœ ì •ë³´ëŸ‰ì„ ê¸°ë°˜ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë‚´ê·œ ìƒë‹´ì„ ì œê³µí•©ë‹ˆë‹¤.")
async def chat_with_rag(request: ChatRequest):
    """í–¥ìƒëœ ì •ë³´ëŸ‰ ê¸°ë°˜ RAG ìƒë‹´"""
    try:
        if not rag_system or not llm_client:
            raise HTTPException(status_code=503, detail="í–¥ìƒëœ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # conversation_historyë¥¼ Dict í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        conversation_history = []
        for msg in request.conversation_history:
            conversation_history.append({
                "role": msg.role,
                "content": msg.content,
                "context": getattr(msg, 'context', None)
            })
        
        # í–¥ìƒëœ ê²€ìƒ‰ (ëŒ€í­ í™•ì¥ëœ ê²°ê³¼)
        current_results = rag_system.search_with_enhanced_retrieval(
            request.query, 
            top_k=20,  # 8 â†’ 20ìœ¼ë¡œ í™•ì¥
            main_category_filter=request.main_category_filter, 
            min_relevance_score=0.3  # ë” ë‚®ì€ ì„ê³„ê°’
        )
        
        # ëŒ€í­ í™•ì¥ëœ ì»¨í…ìŠ¤íŠ¸ ê²°í•©
        combined_context = rag_system.combine_contexts_with_history(
            current_results, 
            conversation_history, 
            max_total_context=25  # 10 â†’ 25ë¡œ í™•ì¥
        )
        
        # í–¥ìƒëœ ì •ë³´ëŸ‰ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        response = llm_client.generate_response_with_history(
            request.query, 
            combined_context, 
            conversation_history
        )
        
        # í’ˆì§ˆ ë¶„ì„
        high_quality = len([c for c in combined_context if c.get('score', 0) >= 0.7])
        medium_quality = len([c for c in combined_context if 0.5 <= c.get('score', 0) < 0.7])
        low_quality = len([c for c in combined_context if 0.3 <= c.get('score', 0) < 0.5])
        
        context_results = [SearchResult(**ctx) for ctx in combined_context]
        
        return ChatResponse(
            query=request.query,
            response=response,
            context=context_results,
            context_count=len(combined_context),
            context_quality={
                "high_relevance": high_quality,
                "medium_relevance": medium_quality,
                "low_relevance": low_quality
            },
            search_type="í–¥ìƒëœ ë‹¤ì¤‘ì¿¼ë¦¬ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰",
            response_type="ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ ê¸°ë°˜ ëŒ€í™”í˜•",
            enhanced_features=[
                f"ë‹¤ì¤‘ ì¿¼ë¦¬ ê²€ìƒ‰ìœ¼ë¡œ {len(current_results)}ê°œ ì •ë³´ ìˆ˜ì§‘",
                f"ì´ {len(combined_context)}ê°œ ì»¨í…ìŠ¤íŠ¸ í™œìš© (ê¸°ì¡´ 10ê°œ â†’ 25ê°œ)",
                "í–¥ìƒëœ ì²­í‚¹ ì „ëµ ì ìš©",
                "ë‹¤ì–‘ì„± ë³´ì¥ ì•Œê³ ë¦¬ì¦˜ ì ìš©",
                "í™•ì¥ëœ ê²€ìƒ‰ ë²”ìœ„ (top_k: 8â†’20)"
            ]
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ìƒë‹´ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(
            status_code=500, 
            detail=f"ìƒë‹´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.post("/chat_stream", summary="í–¥ìƒëœ ì‹¤ì‹œê°„ ë‚´ê·œ ìƒë‹´", description="í–¥ìƒëœ ì •ë³´ëŸ‰ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë‚´ê·œ ìƒë‹´ì„ ì œê³µí•©ë‹ˆë‹¤.")
async def chat_with_rag_stream(request: StreamChatRequest):
    """í–¥ìƒëœ ì •ë³´ëŸ‰ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ìƒë‹´"""
    try:
        if not rag_system or not llm_client:
            raise HTTPException(status_code=503, detail="í–¥ìƒëœ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # conversation_history ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        conversation_history = request.conversation_history or []
        
        # ëŒ€í­ í–¥ìƒëœ ê²€ìƒ‰
        current_results = rag_system.search_with_enhanced_retrieval(
            request.query, 
            top_k=20,  # 8 â†’ 20ìœ¼ë¡œ í™•ì¥
            main_category_filter=request.main_category_filter, 
            min_relevance_score=0.3
        )
        
        # ëŒ€í­ í™•ì¥ëœ ì»¨í…ìŠ¤íŠ¸ ê²°í•©
        combined_context = rag_system.combine_contexts_with_history(
            current_results, 
            conversation_history, 
            max_total_context=25  # 10 â†’ 25ë¡œ í™•ì¥
        )
        
        def generate():
            try:
                # í–¥ìƒëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì „ì†¡
                high_quality = len([c for c in combined_context if c.get('score', 0) >= 0.7])
                medium_quality = len([c for c in combined_context if 0.5 <= c.get('score', 0) < 0.7])
                low_quality = len([c for c in combined_context if 0.3 <= c.get('score', 0) < 0.5])
                
                context_data = {
                    "type": "context",
                    "query": request.query,
                    "context": combined_context,
                    "context_count": len(combined_context),
                    "context_quality": {
                        "high_relevance": high_quality,
                        "medium_relevance": medium_quality,
                        "low_relevance": low_quality
                    },
                    "search_type": "ëŒ€í­ í™•ì¥ëœ ë‹¤ì¤‘ì¿¼ë¦¬ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰",
                    "enhanced_features": [
                        f"ë‹¤ì¤‘ ì¿¼ë¦¬ ê²€ìƒ‰ìœ¼ë¡œ {len(current_results)}ê°œ ì •ë³´ ìˆ˜ì§‘ (ê¸°ì¡´ 8ê°œ â†’ 20ê°œ)",
                        f"ì´ {len(combined_context)}ê°œ ì»¨í…ìŠ¤íŠ¸ í™œìš© (ê¸°ì¡´ 10ê°œ â†’ 25ê°œ)",
                        "í–¥ìƒëœ ì²­í‚¹ ì „ëµ ì ìš©",
                        "ë‹¤ì–‘ì„± ë³´ì¥ ì•Œê³ ë¦¬ì¦˜ ì ìš©",
                        "í™•ì¥ëœ ê²€ìƒ‰ ë²”ìœ„ë¡œ ë” í’ë¶€í•œ ì •ë³´ ì œê³µ"
                    ]
                }
                yield f"data: {json.dumps(context_data, ensure_ascii=False)}\n\n"
                
                # í–¥ìƒëœ ì •ë³´ëŸ‰ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
                for chunk in llm_client.generate_response_stream_with_history(
                    request.query, 
                    combined_context, 
                    conversation_history
                ):
                    chunk_data = {
                        "type": chunk["type"],
                        "content": chunk["content"]
                    }
                    yield f"data: {json.dumps(chunk_data, ensure_ascii=False)}\n\n"
                
                yield f"data: {json.dumps({'type': 'stream_end'}, ensure_ascii=False)}\n\n"
                
            except Exception as stream_error:
                logger.error(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜: {stream_error}", exc_info=True)
                error_data = {
                    "type": "error",
                    "content": f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(stream_error)}"
                }
                yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                yield f"data: {json.dumps({'type': 'stream_end'}, ensure_ascii=False)}\n\n"
        
        return StreamingResponse(
            generate(),
            media_type='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Headers': 'Content-Type',
                'Access-Control-Allow-Methods': 'POST'
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ìƒë‹´ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(
            status_code=500, 
            detail=f"ìŠ¤íŠ¸ë¦¬ë° ìƒë‹´ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.post("/rebuild_index", summary="ëŒ€í­ í™•ì¥ëœ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•", description="ë‚´ê·œ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¡œë“œí•˜ê³  ëŒ€í­ í™•ì¥ëœ ì¸ë±ìŠ¤ë¥¼ ì¬êµ¬ì¶•í•©ë‹ˆë‹¤.")
async def rebuild_index():
    """ëŒ€í­ í™•ì¥ëœ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
    if not rag_system:
        raise HTTPException(status_code=503, detail="ëŒ€í­ í™•ì¥ëœ RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    if rag_system.load_company_regulations_data("./data_json"):
        if rag_system.rebuild_index():
            stats = rag_system.get_stats()
            return {
                "message": "ëŒ€í­ í™•ì¥ëœ ì¸ë±ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì¬êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤",
                "regulations_count": stats['total_documents'],
                "chunk_statistics": stats.get('chunk_statistics', {}),
                "improvements": "ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰, 2.5ë°° ê²€ìƒ‰ ë²”ìœ„, ì •í™•ë„ ê°œì„ ",
                "enhanced_features": stats.get('enhanced_features', []),
                "performance_boost": {
                    "search_top_k": "8 â†’ 20 (2.5ë°° ì¦ê°€)",
                    "context_window": "10 â†’ 25 (2.5ë°° ì¦ê°€)",
                    "search_candidates": "25 â†’ 60 (2.4ë°° ì¦ê°€)"
                }
            }
        else:
            raise HTTPException(status_code=500, detail="ëŒ€í­ í™•ì¥ëœ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì‹¤íŒ¨")
    else:
        raise HTTPException(status_code=500, detail="ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")

@app.get("/stats", summary="ëŒ€í­ í™•ì¥ëœ ì‹œìŠ¤í…œ í†µê³„", description="ëŒ€í­ í™•ì¥ëœ RAG ì‹œìŠ¤í…œì˜ ìƒì„¸ í†µê³„ì™€ ì„±ëŠ¥ ì§€í‘œë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")
async def get_stats():
    """ëŒ€í­ í™•ì¥ëœ í†µê³„ ì •ë³´"""
    if not rag_system:
        raise HTTPException(status_code=503, detail="ëŒ€í­ í™•ì¥ëœ RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    stats = rag_system.get_stats()
    stats.update({
        "system_type": "ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ ê¸°ë°˜ íšŒì‚¬ ë‚´ê·œ ì‹œìŠ¤í…œ",
        "improvements": [
            "ë‹¤ì¤‘ ì¿¼ë¦¬ ê²€ìƒ‰ (ì›ë³¸ + ë³€í˜• ì¿¼ë¦¬)",
            "í–¥ìƒëœ ì²­í‚¹ ì „ëµ (QA + ì§ˆë¬¸ + ë‹µë³€ + ë¬¸ì¥)",
            "í•˜ì´ë¸Œë¦¬ë“œ ì¬ë­í‚¹ (ë²¡í„° + í‚¤ì›Œë“œ + ë‹¤ì¤‘ì¿¼ë¦¬)",
            "ëŒ€í­ í™•ì¥ëœ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° (ìµœëŒ€ 25ê°œ)",
            "ë‹¤ì–‘ì„± ë³´ì¥ ì•Œê³ ë¦¬ì¦˜",
            "ë” ë‚®ì€ ê´€ë ¨ì„± ì„ê³„ê°’ (0.25)",
            "ì •í™•ì„± ìµœìš°ì„  (Temperature: 0.1)",
            "ë” ê¸´ ì‘ë‹µ í—ˆìš© (2500 í† í°)",
            "2.5ë°° í™•ì¥ëœ ê²€ìƒ‰ ë²”ìœ„ (8â†’20)"
        ],
        "performance_metrics": {
            "search_top_k": 20,
            "context_window": 25,
            "search_limit": 60,
            "min_relevance": 0.25,
            "max_tokens": 2500,
            "temperature": 0.1,
            "expansion_ratio": "2.5x"
        },
        "comparison_with_previous": {
            "search_top_k": "8 â†’ 20 (2.5ë°° ì¦ê°€)",
            "context_window": "10 â†’ 25 (2.5ë°° ì¦ê°€)",
            "search_candidates": "25 â†’ 60 (2.4ë°° ì¦ê°€)",
            "min_relevance": "0.3 â†’ 0.25 (ë” í¬ìš©ì )",
            "expected_improvement": "ë‹µë³€ ì™„ì„±ë„ ë° ì •í™•ë„ ëŒ€í­ í–¥ìƒ"
        }
    })
    return stats

# ì‚¬ìš©ì ì •ì˜ docs ì„¤ì • (ì„ íƒì‚¬í•­)
@app.get("/docs", include_in_schema=False)
async def custom_swagger_ui_html():
    return get_swagger_ui_html(
        openapi_url=app.openapi_url,
        title=app.title + " - Swagger UI",
        oauth2_redirect_url=app.swagger_ui_oauth2_redirect_url,
        swagger_js_url="https://cdn.jsdelivr.net/npm/swagger-ui-dist@5/swagger-ui-bundle.js",
        swagger_css_url="https://cdn.jsdelivr.net/npm/swagger-ui-dist@5/swagger-ui.css",
    )

@app.get("/redoc", include_in_schema=False)
async def redoc_html():
    return get_redoc_html(
        openapi_url=app.openapi_url,
        title=app.title + " - ReDoc",
        redoc_js_url="https://cdn.jsdelivr.net/npm/redoc@2.1.0/bundles/redoc.standalone.js",
    )

# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸
@app.post("/test/simple_chat", summary="ê°„ë‹¨í•œ ì±„íŒ… í…ŒìŠ¤íŠ¸", description="ê°„ë‹¨í•œ í˜•ì‹ìœ¼ë¡œ ì±„íŒ… ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
async def simple_chat_test(request: SimpleTestRequest):
    """ê°„ë‹¨í•œ ì±„íŒ… í…ŒìŠ¤íŠ¸ (ë³µì¡í•œ ëª¨ë¸ ì—†ì´)"""
    try:
        if not rag_system or not llm_client:
            raise HTTPException(status_code=503, detail="ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # í™•ì¥ëœ ê²€ìƒ‰ ìˆ˜í–‰
        results = rag_system.search_with_enhanced_retrieval(
            request.query, 
            top_k=15, 
            main_category_filter=request.category
        )
        
        # ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±
        if results:
            response = llm_client.generate_response_with_history(request.query, results, [])
            return {
                "query": request.query,
                "response": response,
                "found_results": len(results),
                "status": "success",
                "info": "í™•ì¥ëœ ê²€ìƒ‰ìœ¼ë¡œ ë” í’ë¶€í•œ ì •ë³´ ì œê³µ (top_k=15)"
            }
        else:
            return {
                "query": request.query,
                "response": "ê´€ë ¨ëœ ë‚´ê·œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "found_results": 0,
                "status": "no_results"
            }
            
    except Exception as e:
        logger.error(f"âŒ ê°„ë‹¨í•œ ì±„íŒ… í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")

@app.get("/test/stream_simple", summary="ê°„ë‹¨í•œ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸", description="ê°„ë‹¨í•œ ìŠ¤íŠ¸ë¦¬ë° ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
async def simple_stream_test(query: str = "íœ´ê°€ ì‹ ì²­ ë°©ë²•"):
    """ê°„ë‹¨í•œ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸"""
    try:
        def generate():
            try:
                yield f"data: {json.dumps({'type': 'start', 'message': f'ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘: {query}'}, ensure_ascii=False)}\n\n"
                
                if not rag_system or not llm_client:
                    yield f"data: {json.dumps({'type': 'error', 'content': 'ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}, ensure_ascii=False)}\n\n"
                    return
                
                # í™•ì¥ëœ ê²€ìƒ‰
                results = rag_system.search_with_enhanced_retrieval(query, top_k=10)
                yield f"data: {json.dumps({'type': 'info', 'message': f'{len(results)}ê°œ ê²°ê³¼ ë°œê²¬ (í™•ì¥ëœ ê²€ìƒ‰)'}, ensure_ascii=False)}\n\n"
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
                for chunk in llm_client.generate_response_stream_with_history(query, results, []):
                    yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"
                    
                yield f"data: {json.dumps({'type': 'stream_end'}, ensure_ascii=False)}\n\n"
                
            except Exception as e:
                logger.error(f"âŒ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
                yield f"data: {json.dumps({'type': 'error', 'content': f'ì˜¤ë¥˜: {str(e)}'}, ensure_ascii=False)}\n\n"
        
        return StreamingResponse(
            generate(),
            media_type='text/event-stream',
            headers={'Cache-Control': 'no-cache'}
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")

# ì‹œì‘ ì´ë²¤íŠ¸
@app.on_event("startup")
async def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì‹¤í–‰"""
    initialize_system()

if __name__ == '__main__':
    print("=" * 80)
    print("ğŸ¢ FastAPI ê¸°ë°˜ ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ íšŒì‚¬ ë‚´ê·œ RAG ì„œë²„")
    print("=" * 80)
    print("âœ¨ ì£¼ìš” ê°œì„ ì‚¬í•­:")
    print("   ğŸ” ë‹¤ì¤‘ ì¿¼ë¦¬ ê²€ìƒ‰ (ì›ë³¸ + ë³€í˜• ì¿¼ë¦¬ë¡œ ë‹¤ê°ë„ ê²€ìƒ‰)")
    print("   ğŸ“ í–¥ìƒëœ ì²­í‚¹ ì „ëµ (QA + ì§ˆë¬¸ + ë‹µë³€ + ë¬¸ì¥ ë‹¨ìœ„)")
    print("   ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ ì¬ë­í‚¹ (ë²¡í„° + í‚¤ì›Œë“œ + ë‹¤ì¤‘ì¿¼ë¦¬ ë§¤ì¹­)")
    print("   ğŸ“Š ëŒ€í­ í™•ì¥ëœ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° (10ê°œ â†’ 25ê°œ, 2.5ë°°)")
    print("   ğŸŒŸ ë‹¤ì–‘ì„± ë³´ì¥ ì•Œê³ ë¦¬ì¦˜ (ì¤‘ë³µ ì œê±° + í’ˆì§ˆ ìœ ì§€)")
    print("   ğŸ“‰ ë” ë‚®ì€ ê´€ë ¨ì„± ì„ê³„ê°’ (0.3 â†’ 0.25, ë” ë§ì€ ì •ë³´)")
    print("   ğŸ¯ ì •í™•ì„± ìµœìš°ì„  (Temperature: 0.1)")
    print("   ğŸ“ ë” ê¸´ ì‘ë‹µ í—ˆìš© (2500 í† í°)")
    print("   âš¡ í–¥ìƒëœ íƒ€ì„ì•„ì›ƒ (120ì´ˆ)")
    print("   ğŸ› ï¸ FastAPI + Swagger UI ì§€ì›")
    print("   ğŸš€ ëŒ€í­ í™•ì¥ëœ ê²€ìƒ‰ ë²”ìœ„ (8ê°œ â†’ 20ê°œ, 2.5ë°°)")
    print("=" * 80)
    print("ğŸ“Š ì„±ëŠ¥ ì§€í‘œ ë¹„êµ:")
    print("   ê²€ìƒ‰ ê²°ê³¼ ìˆ˜     : 8ê°œ  â†’ 20ê°œ  (2.5ë°° â¬†)")
    print("   ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°   : 10ê°œ â†’ 25ê°œ  (2.5ë°° â¬†)")
    print("   ê²€ìƒ‰ í›„ë³´ ìˆ˜     : 25ê°œ â†’ 60ê°œ  (2.4ë°° â¬†)")
    print("   ê´€ë ¨ì„± ì„ê³„ê°’    : 0.3  â†’ 0.25 (ë” í¬ìš©ì )")
    print("=" * 80)
    print("ğŸ”§ FastAPI ì—”ë“œí¬ì¸íŠ¸:")
    print("   - GET  /health            : ëŒ€í­ í™•ì¥ëœ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
    print("   - POST /search            : í™•ì¥ëœ ë‹¤ì¤‘ì¿¼ë¦¬ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰")
    print("   - POST /chat              : ëŒ€í­ í™•ì¥ëœ ì •ë³´ëŸ‰ ê¸°ë°˜ ìƒë‹´")
    print("   - POST /chat_stream       : ëŒ€í­ í™•ì¥ëœ ì‹¤ì‹œê°„ ìƒë‹´ âš¡")
    print("   - POST /rebuild_index     : í–¥ìƒëœ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•")
    print("   - GET  /stats             : í™•ì¥ëœ ì„±ëŠ¥ ì§€í‘œ í¬í•¨ í†µê³„")
    print("   - POST /test/simple_chat  : ğŸ§ª ê°„ë‹¨í•œ ì±„íŒ… í…ŒìŠ¤íŠ¸ (top_k=15)")
    print("   - GET  /test/stream_simple: ğŸ§ª ê°„ë‹¨í•œ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸ (top_k=10)")
    print("   - GET  /docs              : ğŸ¯ Swagger UI ë¬¸ì„œ (API í…ŒìŠ¤íŠ¸ ê°€ëŠ¥) ğŸ¯")
    print("   - GET  /redoc             : ReDoc ë¬¸ì„œ")
    print("=" * 80)
    print("ğŸ“– API ë¬¸ì„œ ë° í…ŒìŠ¤íŠ¸:")
    print("   http://localhost:5000/docs  â† ğŸ¯ ì—¬ê¸°ì„œ API í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”!")
    print("   http://localhost:5000/redoc â† ëŒ€ì•ˆ ë¬¸ì„œ")
    print("=" * 80)
    print("ğŸ§ª 422 ì˜¤ë¥˜ í•´ê²° ê°€ì´ë“œ:")
    print("   1. /test/simple_chatìœ¼ë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš” (JSON body ì‚¬ìš©)")
    print("   2. query í•„ë“œëŠ” ë°˜ë“œì‹œ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤")
    print("   3. conversation_historyëŠ” ë¹ˆ ë°°ì—´ []ë¡œ ì‹œì‘í•˜ì„¸ìš”")
    print("   4. /docs í˜ì´ì§€ì—ì„œ 'Try it out' ë²„íŠ¼ ì‚¬ìš© ê¶Œì¥")
    print("   5. POST ìš”ì²­ì‹œ Content-Type: application/json í•„ìˆ˜")
    print("=" * 80)
    print("ğŸ“ ì‚¬ìš© ì˜ˆì œ (í™•ì¥ëœ ê²€ìƒ‰):")
    print("   curl -X POST 'http://localhost:5000/test/simple_chat' \\")
    print("        -H 'Content-Type: application/json' \\")
    print("        -d '{\"query\": \"21ë…„ì°¨ íœ´ê°€\", \"category\": null}'")
    print("   ë˜ëŠ”")
    print("   curl -X POST 'http://localhost:5000/test/simple_chat' \\")
    print("        -H 'Content-Type: application/json' \\")
    print("        -d '{\"query\": \"íœ´ê°€ ì‹ ì²­ ë°©ë²•\", \"category\": \"ì¸ì‚¬\"}'")
    print("=" * 80)
    print("ğŸ¯ ê¸°ëŒ€ íš¨ê³¼:")
    print("   âœ… 2.5ë°° ë” ë§ì€ ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘")
    print("   âœ… ë” ì™„ì „í•˜ê³  ì •í™•í•œ ë‹µë³€ ìƒì„±")
    print("   âœ… ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ í¬ê´„ì  ëŒ€ë‹µ")
    print("   âœ… ë†“ì¹˜ê¸° ì‰¬ìš´ ê´€ë ¨ ê·œì •ê¹Œì§€ í¬í•¨")
    print("=" * 80)
    
    # í–¥ìƒëœ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    initialize_system() 
    
    logger.info("ğŸš€ ëŒ€í­ í™•ì¥ëœ FastAPI ì„œë²„ ì‹œì‘ ì¤‘...")
    
    # ì§ì ‘ FastAPI ì•± ì‹¤í–‰ (WSGIMiddleware ì œê±°)
    uvicorn.run(app, host='0.0.0.0', port=5000, log_level="info")